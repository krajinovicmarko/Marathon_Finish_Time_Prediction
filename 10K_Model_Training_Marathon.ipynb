{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Machine Learning Marathon finish time estimation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to create a machine learning model for predicting marathon finish times based on age, gender, and 10 km race time running at a marathon pace. This notebook is an extension of the previous one, which utilized the 5km race time.. The model is designed for runners who are already capable of completing a full marathon, as it will be trained on data from runners who have successfully finished the entire marathon distance. This predictive tool can be valuable for individuals preparing for a marathon, providing an estimate of their potential marathon finish time. This is particularly useful since many marathoners typically do not run more than 32-35 km during their training for a marathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from operator import itemgetter\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,RobustScaler,MinMaxScaler,OrdinalEncoder,FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Read the Dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load data on finishers from the Boston Marathon for the years of 2015, 2016 and 2017. Dataset can be accessed via this link [Boston dataset](https://www.kaggle.com/datasets/rojour/boston-results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, glob.glob('dataset/*.csv')))\n",
    "df = df[['Age','M/F','10K','Official Time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Clean data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data by removing unwanted or empty values. For the 'Gender' attribute, only 'M' or 'F' values are allowed. The 'Age' should be any number between 18 and 100. The '10K time' should be represented in the string format 'h:mm:ss'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transforming data\n",
      "\n",
      "Age - 0.00%\n",
      "M/F - 0.00%\n",
      "10K - 0.00%\n",
      "Official Time - 0.00%\n",
      "After transforming data\n",
      "\n",
      "Age - 0.0000%\n",
      "M/F - 0.0000%\n",
      "10K - 0.0014%\n",
      "Official Time - 0.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Before transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.2f}%'.format(col,pct_missing))\n",
    "\n",
    "def process_gender(value):\n",
    "    if value in ('M', 'F'):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "\n",
    "def process_age(value):\n",
    "    if (value >=18 and value <=100):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "    \n",
    "def process_time(value):\n",
    "    if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match((value))):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA \n",
    "    \n",
    "\n",
    "df['M/F'] = df['M/F'].apply(process_gender)\n",
    "df['Age'] = df['Age'].apply(process_age)\n",
    "df['10K'] = df['10K'].apply(process_time)\n",
    "df['Official Time'] = df['Official Time'].apply(process_time)\n",
    "\n",
    "print('After transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.4f}%'.format(col,pct_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying transformations to the dataset, which resulted in only a small number of null values, these rows will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Define Transformers</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop a Custom Transformer for age categorization. The input will be an age number, and the output should represent age categories such as '18-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', and '80+'. \n",
    "\n",
    "Additionally, let's define a FunctionTransformer to convert the '10K time' from the string format 'h:mm:ss' to the numerical feature representing the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].apply(lambda x: pd.cut(x, bins = [0,34,39,44,49,54,59,64,69,74,79,100], labels=['18-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']))\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols\n",
    "\n",
    "class convert_to_seconds(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].applymap(lambda x: pd.to_timedelta(x).total_seconds() if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match(str(x))) else None)\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Preprocessing Pipeline</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a ColumnTransformer, which will be utilized for transforming each column. Within the ColumnTransformer, pipelines are employed to make column transformations flexible and prevent data leakage during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Official Time'],axis=1)\n",
    "\n",
    "enc = convert_to_seconds(input_cols=['Official Time'], output_cols=['Official Time'])\n",
    "Y = enc.transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "preprocessors = ColumnTransformer([\n",
    "    \n",
    "    ('age_pipeline',Pipeline([\n",
    "        ('age_transformed',AgeTransformer(input_cols=['Age'], output_cols=['Age'])),\n",
    "        ('age_encoder',OneHotEncoder(sparse_output = False))       \n",
    "        ]),[\"Age\"]),\n",
    "    \n",
    " \n",
    "    ('gender_pipeline',Pipeline([('gender_encoder',OrdinalEncoder())]), ['M/F']),\n",
    "    \n",
    "    \n",
    "    ('10K_pipeline',Pipeline([\n",
    "        ('time_transformed',convert_to_seconds(input_cols=[\"10K\"], output_cols=[\"10K\"])),   \n",
    "        ('minmax_scaler',MinMaxScaler())     \n",
    "        ]),[\"10K\"])\n",
    "    \n",
    "    ])\n",
    "\n",
    "# X_train_transformed  = preprocessors.fit_transform(X_train)\n",
    "# X_train_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_train_transformed = pd.DataFrame(X_train_transformed, columns = X_train_transformed_names)\n",
    "\n",
    "# X_test_transformed = preprocessors.transform(X_test)\n",
    "# X_test_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_test_transformed = pd.DataFrame(X_test_transformed, columns = X_test_transformed_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">RandomizedSearchCV</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will create pipelines that include a preprocessor and an ML model. These pipelines will be utilized in combination with predefined parameters to evaluate each model using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lasso = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LASSO', Lasso())\n",
    "])\n",
    "\n",
    "pipe_ridge = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RIDGE', Ridge())\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('KNN', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('SVR', SVR())\n",
    "])\n",
    "\n",
    "pipe_et = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ET', ExtraTreesRegressor())\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('DT', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RF', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ADA', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_gbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('GBR', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "pipe_lgbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LGBR', lgb.LGBMRegressor())\n",
    "])\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('CAT', CatBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('XGB', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "lasso_param_grid = [{'LASSO__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "ridge_param_grid = [{'RIDGE__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "\n",
    "knn_param_grid = [{                 \n",
    "                    'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "                    'KNN__weights': ['uniform', 'distance'],\n",
    "                    'KNN__p': [1, 2],             \n",
    "                    }]\n",
    "\n",
    "\n",
    "et_param_grid = [{                 \n",
    "                    'ET__n_estimators': [50, 100, 200],\n",
    "                    'ET__max_depth': [None, 5, 10, 15],\n",
    "                    'ET__min_samples_split': [2, 5, 10],\n",
    "                    'ET__min_samples_leaf': [1, 2, 4],\n",
    "                    'ET__max_features': [1.0, 'sqrt', 'log2']       \n",
    "                    }]\n",
    "\n",
    "dt_param_grid = [{                 \n",
    "                    'DT__max_depth': [None, 5, 10, 15],\n",
    "                    'DT__min_samples_split': [2, 5, 10],\n",
    "                    'DT__min_samples_leaf': [1, 2, 4]          \n",
    "                    }]\n",
    "\n",
    "rf_param_grid = [{                 \n",
    "                    'RF__n_estimators': [50, 100, 200],\n",
    "                    'RF__max_features': [1.0, 'sqrt', 'log2'],\n",
    "                    'RF__max_depth': [None, 10, 20, 30],\n",
    "                    'RF__min_samples_split': [2, 5, 10],\n",
    "                    'RF__min_samples_leaf': [1, 2, 4],\n",
    "                    'RF__bootstrap': [True, False]               \n",
    "                    }]\n",
    "\n",
    "ada_param_grid = [{                 \n",
    "                    'ADA__n_estimators': [50, 100, 200],\n",
    "                    'ADA__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'ADA__loss': ['linear', 'square', 'exponential']            \n",
    "                    }]\n",
    "\n",
    "gbr_param_grid = [{                 \n",
    "                    'GBR__n_estimators': [50, 100, 200],\n",
    "                    'GBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'GBR__max_depth': [3, 5, 7],\n",
    "                    'GBR__subsample': [0.8, 0.9, 1.0]          \n",
    "                    }]\n",
    "\n",
    "lgbr_param_grid = [{                 \n",
    "                    'LGBR__n_estimators': [50, 100, 200],\n",
    "                    'LGBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'LGBR__max_depth': [3, 5, 7],\n",
    "                    'LGBR__subsample': [0.8, 0.9, 1.0],\n",
    "                    'LGBR__colsample_bytree': [0.8, 0.9, 1.0]         \n",
    "                    }]\n",
    "\n",
    "cat_param_grid = [{                 \n",
    "                    'CAT__iterations': [50, 100, 200],\n",
    "                    'CAT__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'CAT__depth': [3, 5, 7],\n",
    "                    'CAT__l2_leaf_reg': [1, 3, 5],\n",
    "                    'CAT__subsample': [0.8, 0.9, 1.0]        \n",
    "                    }]\n",
    "\n",
    "\n",
    "xgb_param_grid = [{                 \n",
    "                    'XGB__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'XGB__n_estimators': [50, 100, 200],\n",
    "                    'XGB__max_depth': [3, 5, 7],\n",
    "                    'XGB__subsample': [0.8, 0.9, 1.0],\n",
    "                    'XGB__colsample_bytree': [0.8, 0.9, 1.0]             \n",
    "                    }]\n",
    "\n",
    "\n",
    "lasso_grid_search = RandomizedSearchCV(estimator=pipe_lasso,\n",
    "        param_distributions=lasso_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ridge_grid_search = RandomizedSearchCV(estimator=pipe_ridge,\n",
    "        param_distributions=ridge_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "knn_grid_search = RandomizedSearchCV(estimator=pipe_knn,\n",
    "        param_distributions=knn_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "et_grid_search = RandomizedSearchCV(estimator=pipe_et,\n",
    "        param_distributions=et_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "dt_grid_search = RandomizedSearchCV(estimator=pipe_dt,\n",
    "        param_distributions=dt_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "rf_grid_search = RandomizedSearchCV(estimator=pipe_rf,\n",
    "        param_distributions=rf_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ada_grid_search = RandomizedSearchCV(estimator=pipe_ada,\n",
    "        param_distributions=ada_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "gbr_grid_search = RandomizedSearchCV(estimator=pipe_gbr,\n",
    "        param_distributions=gbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "lgbr_grid_search = RandomizedSearchCV(estimator=pipe_lgbr,\n",
    "        param_distributions=lgbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "cat_grid_search = RandomizedSearchCV(estimator=pipe_cat,\n",
    "        param_distributions=cat_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "xgb_grid_search = RandomizedSearchCV(estimator=pipe_xgb,\n",
    "        param_distributions=xgb_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Train model and Save results to a text file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e+10, tolerance: 3.962e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LASSO\n",
      "Finished training RIDGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ET\n",
      "Finished training DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training GBR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LGBR\n",
      "0:\tlearn: 2299.4331812\ttotal: 153ms\tremaining: 30.5s\n",
      "1:\tlearn: 2125.2351337\ttotal: 167ms\tremaining: 16.5s\n",
      "2:\tlearn: 1971.4627456\ttotal: 181ms\tremaining: 11.9s\n",
      "3:\tlearn: 1838.7956494\ttotal: 195ms\tremaining: 9.55s\n",
      "4:\tlearn: 1718.9238114\ttotal: 209ms\tremaining: 8.15s\n",
      "5:\tlearn: 1615.1392037\ttotal: 222ms\tremaining: 7.19s\n",
      "6:\tlearn: 1523.1902384\ttotal: 235ms\tremaining: 6.48s\n",
      "7:\tlearn: 1444.0586296\ttotal: 247ms\tremaining: 5.94s\n",
      "8:\tlearn: 1377.2752292\ttotal: 262ms\tremaining: 5.55s\n",
      "9:\tlearn: 1320.0949261\ttotal: 273ms\tremaining: 5.19s\n",
      "10:\tlearn: 1271.0025243\ttotal: 286ms\tremaining: 4.91s\n",
      "11:\tlearn: 1227.9772520\ttotal: 297ms\tremaining: 4.65s\n",
      "12:\tlearn: 1191.6098972\ttotal: 309ms\tremaining: 4.44s\n",
      "13:\tlearn: 1161.2247735\ttotal: 321ms\tremaining: 4.27s\n",
      "14:\tlearn: 1135.9648356\ttotal: 334ms\tremaining: 4.12s\n",
      "15:\tlearn: 1114.7965978\ttotal: 345ms\tremaining: 3.97s\n",
      "16:\tlearn: 1096.9225531\ttotal: 358ms\tremaining: 3.85s\n",
      "17:\tlearn: 1082.0320552\ttotal: 370ms\tremaining: 3.74s\n",
      "18:\tlearn: 1069.5570161\ttotal: 383ms\tremaining: 3.65s\n",
      "19:\tlearn: 1059.0159523\ttotal: 395ms\tremaining: 3.56s\n",
      "20:\tlearn: 1050.2258497\ttotal: 407ms\tremaining: 3.47s\n",
      "21:\tlearn: 1042.9833499\ttotal: 419ms\tremaining: 3.39s\n",
      "22:\tlearn: 1036.6703093\ttotal: 431ms\tremaining: 3.32s\n",
      "23:\tlearn: 1031.6634124\ttotal: 443ms\tremaining: 3.25s\n",
      "24:\tlearn: 1027.1652767\ttotal: 457ms\tremaining: 3.2s\n",
      "25:\tlearn: 1023.5458995\ttotal: 472ms\tremaining: 3.16s\n",
      "26:\tlearn: 1020.5978941\ttotal: 486ms\tremaining: 3.11s\n",
      "27:\tlearn: 1017.8515594\ttotal: 500ms\tremaining: 3.07s\n",
      "28:\tlearn: 1015.6479942\ttotal: 513ms\tremaining: 3.02s\n",
      "29:\tlearn: 1013.8677927\ttotal: 525ms\tremaining: 2.98s\n",
      "30:\tlearn: 1012.2278319\ttotal: 537ms\tremaining: 2.93s\n",
      "31:\tlearn: 1010.9585894\ttotal: 549ms\tremaining: 2.88s\n",
      "32:\tlearn: 1009.8484964\ttotal: 561ms\tremaining: 2.84s\n",
      "33:\tlearn: 1008.8652778\ttotal: 574ms\tremaining: 2.8s\n",
      "34:\tlearn: 1008.2209912\ttotal: 587ms\tremaining: 2.77s\n",
      "35:\tlearn: 1007.4543136\ttotal: 602ms\tremaining: 2.74s\n",
      "36:\tlearn: 1006.7873146\ttotal: 618ms\tremaining: 2.72s\n",
      "37:\tlearn: 1006.3390344\ttotal: 631ms\tremaining: 2.69s\n",
      "38:\tlearn: 1005.8603785\ttotal: 643ms\tremaining: 2.65s\n",
      "39:\tlearn: 1005.4581644\ttotal: 656ms\tremaining: 2.62s\n",
      "40:\tlearn: 1005.0229251\ttotal: 667ms\tremaining: 2.59s\n",
      "41:\tlearn: 1004.7332249\ttotal: 678ms\tremaining: 2.55s\n",
      "42:\tlearn: 1004.3841853\ttotal: 690ms\tremaining: 2.52s\n",
      "43:\tlearn: 1004.1930827\ttotal: 698ms\tremaining: 2.47s\n",
      "44:\tlearn: 1003.9539802\ttotal: 709ms\tremaining: 2.44s\n",
      "45:\tlearn: 1003.7537665\ttotal: 720ms\tremaining: 2.41s\n",
      "46:\tlearn: 1003.5769840\ttotal: 732ms\tremaining: 2.38s\n",
      "47:\tlearn: 1003.3741085\ttotal: 745ms\tremaining: 2.36s\n",
      "48:\tlearn: 1003.2415839\ttotal: 757ms\tremaining: 2.33s\n",
      "49:\tlearn: 1003.0735968\ttotal: 771ms\tremaining: 2.31s\n",
      "50:\tlearn: 1002.9548840\ttotal: 783ms\tremaining: 2.29s\n",
      "51:\tlearn: 1002.7422917\ttotal: 797ms\tremaining: 2.27s\n",
      "52:\tlearn: 1002.5969946\ttotal: 810ms\tremaining: 2.25s\n",
      "53:\tlearn: 1002.4979264\ttotal: 822ms\tremaining: 2.22s\n",
      "54:\tlearn: 1002.3729746\ttotal: 835ms\tremaining: 2.2s\n",
      "55:\tlearn: 1002.2947691\ttotal: 846ms\tremaining: 2.17s\n",
      "56:\tlearn: 1002.2042617\ttotal: 858ms\tremaining: 2.15s\n",
      "57:\tlearn: 1002.0915842\ttotal: 870ms\tremaining: 2.13s\n",
      "58:\tlearn: 1002.0172101\ttotal: 882ms\tremaining: 2.11s\n",
      "59:\tlearn: 1001.9581368\ttotal: 893ms\tremaining: 2.08s\n",
      "60:\tlearn: 1001.8955057\ttotal: 904ms\tremaining: 2.06s\n",
      "61:\tlearn: 1001.7808808\ttotal: 915ms\tremaining: 2.04s\n",
      "62:\tlearn: 1001.7057619\ttotal: 926ms\tremaining: 2.01s\n",
      "63:\tlearn: 1001.6528192\ttotal: 938ms\tremaining: 1.99s\n",
      "64:\tlearn: 1001.6121141\ttotal: 951ms\tremaining: 1.97s\n",
      "65:\tlearn: 1001.5669573\ttotal: 963ms\tremaining: 1.95s\n",
      "66:\tlearn: 1001.4953636\ttotal: 976ms\tremaining: 1.94s\n",
      "67:\tlearn: 1001.4363938\ttotal: 990ms\tremaining: 1.92s\n",
      "68:\tlearn: 1001.3716670\ttotal: 1s\tremaining: 1.9s\n",
      "69:\tlearn: 1001.3121060\ttotal: 1.01s\tremaining: 1.89s\n",
      "70:\tlearn: 1001.3075589\ttotal: 1.02s\tremaining: 1.85s\n",
      "71:\tlearn: 1001.2638962\ttotal: 1.03s\tremaining: 1.84s\n",
      "72:\tlearn: 1001.2010033\ttotal: 1.04s\tremaining: 1.82s\n",
      "73:\tlearn: 1001.1675054\ttotal: 1.06s\tremaining: 1.8s\n",
      "74:\tlearn: 1001.1563788\ttotal: 1.06s\tremaining: 1.77s\n",
      "75:\tlearn: 1001.1457306\ttotal: 1.07s\tremaining: 1.74s\n",
      "76:\tlearn: 1001.1214015\ttotal: 1.08s\tremaining: 1.73s\n",
      "77:\tlearn: 1001.1135992\ttotal: 1.09s\tremaining: 1.7s\n",
      "78:\tlearn: 1001.0425267\ttotal: 1.1s\tremaining: 1.69s\n",
      "79:\tlearn: 1001.0120460\ttotal: 1.11s\tremaining: 1.67s\n",
      "80:\tlearn: 1000.9816478\ttotal: 1.13s\tremaining: 1.65s\n",
      "81:\tlearn: 1000.9532104\ttotal: 1.14s\tremaining: 1.64s\n",
      "82:\tlearn: 1000.9416597\ttotal: 1.15s\tremaining: 1.62s\n",
      "83:\tlearn: 1000.9278643\ttotal: 1.16s\tremaining: 1.59s\n",
      "84:\tlearn: 1000.9066115\ttotal: 1.17s\tremaining: 1.58s\n",
      "85:\tlearn: 1000.8659148\ttotal: 1.18s\tremaining: 1.56s\n",
      "86:\tlearn: 1000.8641693\ttotal: 1.19s\tremaining: 1.54s\n",
      "87:\tlearn: 1000.8372341\ttotal: 1.2s\tremaining: 1.53s\n",
      "88:\tlearn: 1000.7570890\ttotal: 1.21s\tremaining: 1.51s\n",
      "89:\tlearn: 1000.7203551\ttotal: 1.23s\tremaining: 1.5s\n",
      "90:\tlearn: 1000.6947444\ttotal: 1.24s\tremaining: 1.48s\n",
      "91:\tlearn: 1000.6330952\ttotal: 1.25s\tremaining: 1.47s\n",
      "92:\tlearn: 1000.5835944\ttotal: 1.26s\tremaining: 1.45s\n",
      "93:\tlearn: 1000.5344009\ttotal: 1.27s\tremaining: 1.44s\n",
      "94:\tlearn: 1000.5054464\ttotal: 1.29s\tremaining: 1.42s\n",
      "95:\tlearn: 1000.4587100\ttotal: 1.3s\tremaining: 1.41s\n",
      "96:\tlearn: 1000.4340014\ttotal: 1.31s\tremaining: 1.39s\n",
      "97:\tlearn: 1000.4166974\ttotal: 1.32s\tremaining: 1.38s\n",
      "98:\tlearn: 1000.3725885\ttotal: 1.33s\tremaining: 1.36s\n",
      "99:\tlearn: 1000.3245780\ttotal: 1.35s\tremaining: 1.35s\n",
      "100:\tlearn: 1000.2895960\ttotal: 1.36s\tremaining: 1.33s\n",
      "101:\tlearn: 1000.2431445\ttotal: 1.38s\tremaining: 1.32s\n",
      "102:\tlearn: 1000.1810999\ttotal: 1.39s\tremaining: 1.31s\n",
      "103:\tlearn: 1000.1645483\ttotal: 1.4s\tremaining: 1.29s\n",
      "104:\tlearn: 1000.1331876\ttotal: 1.41s\tremaining: 1.28s\n",
      "105:\tlearn: 1000.0981163\ttotal: 1.43s\tremaining: 1.26s\n",
      "106:\tlearn: 1000.0629758\ttotal: 1.44s\tremaining: 1.25s\n",
      "107:\tlearn: 1000.0151959\ttotal: 1.45s\tremaining: 1.24s\n",
      "108:\tlearn: 999.9757376\ttotal: 1.46s\tremaining: 1.22s\n",
      "109:\tlearn: 999.9188196\ttotal: 1.47s\tremaining: 1.21s\n",
      "110:\tlearn: 999.8874611\ttotal: 1.49s\tremaining: 1.19s\n",
      "111:\tlearn: 999.8432885\ttotal: 1.5s\tremaining: 1.18s\n",
      "112:\tlearn: 999.7924871\ttotal: 1.51s\tremaining: 1.16s\n",
      "113:\tlearn: 999.7641218\ttotal: 1.52s\tremaining: 1.15s\n",
      "114:\tlearn: 999.7263048\ttotal: 1.53s\tremaining: 1.13s\n",
      "115:\tlearn: 999.7039585\ttotal: 1.54s\tremaining: 1.12s\n",
      "116:\tlearn: 999.6728557\ttotal: 1.56s\tremaining: 1.1s\n",
      "117:\tlearn: 999.6236046\ttotal: 1.57s\tremaining: 1.09s\n",
      "118:\tlearn: 999.5694413\ttotal: 1.58s\tremaining: 1.08s\n",
      "119:\tlearn: 999.5210188\ttotal: 1.6s\tremaining: 1.06s\n",
      "120:\tlearn: 999.4977920\ttotal: 1.61s\tremaining: 1.05s\n",
      "121:\tlearn: 999.4676364\ttotal: 1.62s\tremaining: 1.04s\n",
      "122:\tlearn: 999.4468827\ttotal: 1.64s\tremaining: 1.02s\n",
      "123:\tlearn: 999.3933487\ttotal: 1.65s\tremaining: 1.01s\n",
      "124:\tlearn: 999.3365799\ttotal: 1.66s\tremaining: 996ms\n",
      "125:\tlearn: 999.2954050\ttotal: 1.67s\tremaining: 982ms\n",
      "126:\tlearn: 999.2547784\ttotal: 1.68s\tremaining: 967ms\n",
      "127:\tlearn: 999.2166208\ttotal: 1.69s\tremaining: 953ms\n",
      "128:\tlearn: 999.1426447\ttotal: 1.71s\tremaining: 939ms\n",
      "129:\tlearn: 999.0857717\ttotal: 1.72s\tremaining: 925ms\n",
      "130:\tlearn: 999.0589351\ttotal: 1.73s\tremaining: 912ms\n",
      "131:\tlearn: 999.0273160\ttotal: 1.74s\tremaining: 899ms\n",
      "132:\tlearn: 998.9859013\ttotal: 1.76s\tremaining: 885ms\n",
      "133:\tlearn: 998.9451252\ttotal: 1.77s\tremaining: 872ms\n",
      "134:\tlearn: 998.9104670\ttotal: 1.79s\tremaining: 860ms\n",
      "135:\tlearn: 998.8904180\ttotal: 1.8s\tremaining: 846ms\n",
      "136:\tlearn: 998.8661626\ttotal: 1.81s\tremaining: 832ms\n",
      "137:\tlearn: 998.8242243\ttotal: 1.82s\tremaining: 818ms\n",
      "138:\tlearn: 998.7806829\ttotal: 1.83s\tremaining: 804ms\n",
      "139:\tlearn: 998.7257132\ttotal: 1.84s\tremaining: 791ms\n",
      "140:\tlearn: 998.7030951\ttotal: 1.86s\tremaining: 777ms\n",
      "141:\tlearn: 998.6737746\ttotal: 1.87s\tremaining: 763ms\n",
      "142:\tlearn: 998.6324111\ttotal: 1.88s\tremaining: 750ms\n",
      "143:\tlearn: 998.5967738\ttotal: 1.89s\tremaining: 736ms\n",
      "144:\tlearn: 998.5326340\ttotal: 1.9s\tremaining: 722ms\n",
      "145:\tlearn: 998.5068643\ttotal: 1.92s\tremaining: 709ms\n",
      "146:\tlearn: 998.4672005\ttotal: 1.93s\tremaining: 695ms\n",
      "147:\tlearn: 998.3890206\ttotal: 1.94s\tremaining: 682ms\n",
      "148:\tlearn: 998.3526163\ttotal: 1.95s\tremaining: 669ms\n",
      "149:\tlearn: 998.2986326\ttotal: 1.97s\tremaining: 656ms\n",
      "150:\tlearn: 998.2542412\ttotal: 1.98s\tremaining: 643ms\n",
      "151:\tlearn: 998.2238703\ttotal: 2s\tremaining: 630ms\n",
      "152:\tlearn: 998.1763449\ttotal: 2.01s\tremaining: 617ms\n",
      "153:\tlearn: 998.1143943\ttotal: 2.02s\tremaining: 604ms\n",
      "154:\tlearn: 998.0770466\ttotal: 2.03s\tremaining: 590ms\n",
      "155:\tlearn: 998.0447066\ttotal: 2.04s\tremaining: 577ms\n",
      "156:\tlearn: 997.9859478\ttotal: 2.06s\tremaining: 563ms\n",
      "157:\tlearn: 997.9499709\ttotal: 2.07s\tremaining: 550ms\n",
      "158:\tlearn: 997.9250074\ttotal: 2.08s\tremaining: 537ms\n",
      "159:\tlearn: 997.8732138\ttotal: 2.09s\tremaining: 523ms\n",
      "160:\tlearn: 997.7968535\ttotal: 2.1s\tremaining: 510ms\n",
      "161:\tlearn: 997.7737766\ttotal: 2.12s\tremaining: 497ms\n",
      "162:\tlearn: 997.7269693\ttotal: 2.13s\tremaining: 483ms\n",
      "163:\tlearn: 997.6928857\ttotal: 2.14s\tremaining: 470ms\n",
      "164:\tlearn: 997.6591850\ttotal: 2.15s\tremaining: 457ms\n",
      "165:\tlearn: 997.5955603\ttotal: 2.17s\tremaining: 444ms\n",
      "166:\tlearn: 997.5471160\ttotal: 2.18s\tremaining: 431ms\n",
      "167:\tlearn: 997.5156628\ttotal: 2.2s\tremaining: 419ms\n",
      "168:\tlearn: 997.4837886\ttotal: 2.21s\tremaining: 405ms\n",
      "169:\tlearn: 997.4522892\ttotal: 2.22s\tremaining: 392ms\n",
      "170:\tlearn: 997.4266706\ttotal: 2.23s\tremaining: 379ms\n",
      "171:\tlearn: 997.4099647\ttotal: 2.25s\tremaining: 366ms\n",
      "172:\tlearn: 997.3802605\ttotal: 2.26s\tremaining: 352ms\n",
      "173:\tlearn: 997.3428531\ttotal: 2.27s\tremaining: 339ms\n",
      "174:\tlearn: 997.2939220\ttotal: 2.28s\tremaining: 326ms\n",
      "175:\tlearn: 997.2749294\ttotal: 2.29s\tremaining: 313ms\n",
      "176:\tlearn: 997.2231601\ttotal: 2.31s\tremaining: 300ms\n",
      "177:\tlearn: 997.1947583\ttotal: 2.32s\tremaining: 287ms\n",
      "178:\tlearn: 997.1647261\ttotal: 2.33s\tremaining: 273ms\n",
      "179:\tlearn: 997.1396657\ttotal: 2.34s\tremaining: 260ms\n",
      "180:\tlearn: 997.1075556\ttotal: 2.35s\tremaining: 247ms\n",
      "181:\tlearn: 997.0914401\ttotal: 2.37s\tremaining: 234ms\n",
      "182:\tlearn: 997.0405060\ttotal: 2.38s\tremaining: 221ms\n",
      "183:\tlearn: 997.0014726\ttotal: 2.39s\tremaining: 208ms\n",
      "184:\tlearn: 996.9660106\ttotal: 2.41s\tremaining: 195ms\n",
      "185:\tlearn: 996.9246654\ttotal: 2.42s\tremaining: 182ms\n",
      "186:\tlearn: 996.8802976\ttotal: 2.43s\tremaining: 169ms\n",
      "187:\tlearn: 996.8560361\ttotal: 2.44s\tremaining: 156ms\n",
      "188:\tlearn: 996.8175381\ttotal: 2.46s\tremaining: 143ms\n",
      "189:\tlearn: 996.7810959\ttotal: 2.47s\tremaining: 130ms\n",
      "190:\tlearn: 996.7522951\ttotal: 2.48s\tremaining: 117ms\n",
      "191:\tlearn: 996.7277509\ttotal: 2.49s\tremaining: 104ms\n",
      "192:\tlearn: 996.6824770\ttotal: 2.5s\tremaining: 90.8ms\n",
      "193:\tlearn: 996.6530667\ttotal: 2.52s\tremaining: 77.8ms\n",
      "194:\tlearn: 996.6251456\ttotal: 2.53s\tremaining: 64.8ms\n",
      "195:\tlearn: 996.5927094\ttotal: 2.54s\tremaining: 51.9ms\n",
      "196:\tlearn: 996.5611608\ttotal: 2.56s\tremaining: 38.9ms\n",
      "197:\tlearn: 996.5373783\ttotal: 2.57s\tremaining: 26ms\n",
      "198:\tlearn: 996.4937582\ttotal: 2.58s\tremaining: 13ms\n",
      "199:\tlearn: 996.4315181\ttotal: 2.6s\tremaining: 0us\n",
      "Finished training CAT\n",
      "Finished training XGB\n"
     ]
    }
   ],
   "source": [
    "grids = [lasso_grid_search,\n",
    "         ridge_grid_search,\n",
    "         knn_grid_search,\n",
    "         et_grid_search,\n",
    "         dt_grid_search,\n",
    "         rf_grid_search,\n",
    "         ada_grid_search,\n",
    "         gbr_grid_search,\n",
    "         lgbr_grid_search,\n",
    "         cat_grid_search,\n",
    "         xgb_grid_search\n",
    "         ]\n",
    "\n",
    "for pipe in grids:\n",
    "    pipe.fit(X_train,y_train)\n",
    "    print('Finished training {}'.format(pipe.estimator.steps[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will save results of the training and model evaluations will in txt and csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso Test metric: -728.9397999121562\n",
      "lasso Best Params: {'LASSO__alpha': 1e-15}\n",
      "ridge Test metric: -728.9397999121825\n",
      "ridge Best Params: {'RIDGE__alpha': 1e-10}\n",
      "knn Test metric: -763.3503923790339\n",
      "knn Best Params: {'KNN__weights': 'uniform', 'KNN__p': 2, 'KNN__n_neighbors': 9}\n",
      "et Test metric: -737.5140526579171\n",
      "et Best Params: {'ET__n_estimators': 100, 'ET__min_samples_split': 10, 'ET__min_samples_leaf': 1, 'ET__max_features': 'sqrt', 'ET__max_depth': 15}\n",
      "dt Test metric: -736.3595661869911\n",
      "dt Best Params: {'DT__min_samples_split': 2, 'DT__min_samples_leaf': 2, 'DT__max_depth': 5}\n",
      "rf Test metric: -728.4010508369535\n",
      "rf Best Params: {'RF__n_estimators': 100, 'RF__min_samples_split': 2, 'RF__min_samples_leaf': 4, 'RF__max_features': 1.0, 'RF__max_depth': 10, 'RF__bootstrap': True}\n",
      "ada Test metric: -785.9356511527182\n",
      "ada Best Params: {'ADA__n_estimators': 200, 'ADA__loss': 'linear', 'ADA__learning_rate': 0.01}\n",
      "gbr Test metric: -725.9847986525255\n",
      "gbr Best Params: {'GBR__subsample': 0.8, 'GBR__n_estimators': 100, 'GBR__max_depth': 3, 'GBR__learning_rate': 0.1}\n",
      "lgbr Test metric: -726.4192537246118\n",
      "lgbr Best Params: {'LGBR__subsample': 0.9, 'LGBR__n_estimators': 100, 'LGBR__max_depth': 5, 'LGBR__learning_rate': 0.1, 'LGBR__colsample_bytree': 0.9}\n",
      "cat Test metric: -727.0892303590382\n",
      "cat Best Params: {'CAT__subsample': 0.8, 'CAT__learning_rate': 0.1, 'CAT__l2_leaf_reg': 3, 'CAT__iterations': 200, 'CAT__depth': 7}\n",
      "xgb Test metric: -715.866597019634\n",
      "xgb Best Params: {'XGB__subsample': 0.9, 'XGB__n_estimators': 50, 'XGB__max_depth': 5, 'XGB__learning_rate': 0.1, 'XGB__colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "grid_dict = {\n",
    "                0: 'lasso',\n",
    "                1: 'ridge',\n",
    "                2: 'knn',\n",
    "                3: 'et',\n",
    "                4: 'dt',\n",
    "                5: 'rf',\n",
    "                6: 'ada',\n",
    "                7: 'gbr',\n",
    "                8: 'lgbr',\n",
    "                9:'cat',\n",
    "                10:'xgb'\n",
    "                }\n",
    "\n",
    "results = []\n",
    "for i, model in enumerate(grids):\n",
    "    print('{} Test metric: {}'.format(grid_dict[i],\n",
    "    model.score(X_test,y_test)))\n",
    "    print('{} Best Params: {}'.format(grid_dict[i], model.best_params_))\n",
    "    y_true, y_pred = y_test, model.best_estimator_.predict(X_test),\n",
    "    \n",
    "    results.append({    \n",
    "        'iterator': i,\n",
    "        'model': grid_dict[i],\n",
    "        'best_params': model.best_params_,\n",
    "        'best_score': model.best_score_,\n",
    "        'mae': mean_absolute_error(y_true,y_pred),\n",
    "        'mse': mean_squared_error(y_true,y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true,y_pred)),\n",
    "        'r2': r2_score(y_true,y_pred)\n",
    "        })\n",
    "    \n",
    "results = sorted(results, key=itemgetter('best_score'), reverse=True) \n",
    "\n",
    " \n",
    "with open('results/10K_grid_search_results.txt', 'w') as file:\n",
    "    for result in results:\n",
    "        file.write(f\"Model: {result['model']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(\"Best Parameters:\\n\")\n",
    "        for key, value in result['best_params'].items():\n",
    "            file.write(f\"{key}: {value}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(f\"Best Score: {result['best_score']}\\n\")\n",
    "        file.write(f\"mae: {result['mae']}\\n\")\n",
    "        file.write(f\"mse: {result['mse']}\\n\")\n",
    "        file.write(f\"rmse: {result['rmse']}\\n\")\n",
    "        file.write(f\"r2: {result['r2']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "models_scores = pd.DataFrame(results)\n",
    "models_scores = models_scores[['model','mae','mse','rmse','r2']]\n",
    "models_scores.to_csv('results/10K_models_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how did models performed on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model         mae           mse         rmse        r2\n",
      "0     xgb  715.866597  9.879748e+05   993.969214  0.837536\n",
      "1     gbr  725.984799  9.834525e+05   991.691723  0.838280\n",
      "2     cat  727.089230  9.857622e+05   992.855569  0.837900\n",
      "3    lgbr  726.419254  9.852790e+05   992.612186  0.837980\n",
      "4   lasso  728.939800  9.917807e+05   995.881851  0.836910\n",
      "5   ridge  728.939800  9.917807e+05   995.881851  0.836910\n",
      "6      rf  728.401051  9.914415e+05   995.711535  0.836966\n",
      "7      dt  736.359566  1.010265e+06  1005.119401  0.833871\n",
      "8      et  737.514053  9.972792e+05   998.638670  0.836006\n",
      "9     knn  763.350392  1.082737e+06  1040.546551  0.821954\n",
      "10    ada  785.935651  1.099163e+06  1048.409806  0.819252\n"
     ]
    }
   ],
   "source": [
    "print(models_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it appears that all models are performing well. We can observe R2 values within the range of 0.82-0.84 (using 5K time it was 0.77-0.80), and MAE falls between 715-785 (using 5K time it was 819-882 seconds), which is satisfactory given that we are attempting to predict marathon finish time based on age, gender, and 10K race time. It is evident that the model trained with 10 km race times provides better predictions, as anticipated. I expect that its performance will further enhance when incorporating 21 km race times as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Saving best model and making prediction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best model XGB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/10K_best_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = grids[results[0]['iterator']]\n",
    "print('Found best model {}'.format(best_model.estimator.steps[-1][0]))\n",
    "\n",
    "joblib.dump(best_model, 'models/10K_best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and making predictions for myself! üòÅ (Even though I can typically run 10 km faster, this would be my expected time during longer runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My predicted marathon time in hh:mm:ss is: 3:42:30\n",
      "My predicted marathon time in hh:mm:ss is: 3:35:39\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "best_model_loaded = joblib.load(\"models/10K_best_model.pkl\") \n",
    "\n",
    "# Testing mysef\n",
    "d = {'Age': [30], 'M/F': ['M'], '10K': ['0:48:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))\n",
    "\n",
    "# Testing mysef as female\n",
    "d = {'Age': [30], 'M/F': ['F'], '10K': ['0:48:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current predictions from the model are quite accurate, especially considering that my best marathon time is around 3:40:00. Considering this, training the model using 21 km time may lead to even better results. Additionally, an interesting observation is that changing the gender from male to female seems to improve the predicted outcomes. This aligns with known information on the subject, as explored in the Exploratory Data Analysis (EDA) notebook, suggesting that females generally exhibit better endurance than males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A machine learning model has been successfully developed for predicting marathon finish times, leveraging features such as age, gender, and 10 km race time. The results demonstrate the model's effectiveness. Future efforts will involve the development of additional models to enhance predictive capabilities using alternative features, such as 21 km race times. It is anticipated that these extended model will further improve the accuracy and precision of predictions for marathon finish times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
