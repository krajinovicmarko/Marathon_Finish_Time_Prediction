{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Machine Learning Marathon finish time estimation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to create a machine learning model for predicting marathon finish times based on age, gender, and 21.1 km (Half marathon time) race time running at a marathon pace. This notebook is an extension of the previous one, which utilized the 5km race time.. The model is designed for runners who are already capable of completing a full marathon, as it will be trained on data from runners who have successfully finished the entire marathon distance. This predictive tool can be valuable for individuals preparing for a marathon, providing an estimate of their potential marathon finish time. This is particularly useful since many marathoners typically do not run more than 32-35 km during their training for a marathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from operator import itemgetter\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,RobustScaler,MinMaxScaler,OrdinalEncoder,FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:21px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Read the Dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load data on finishers from the Boston Marathon for the years of 2015, 2016 and 2017. Dataset can be accessed via this link [Boston dataset](https://www.kaggle.com/datasets/rojour/boston-results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, glob.glob('dataset/*.csv')))\n",
    "df = df[['Age','M/F','Half','Official Time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Clean data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data by removing unwanted or empty values. For the 'Gender' attribute, only 'M' or 'F' values are allowed. The 'Age' should be any number between 18 and 100. The 'Half marathon time' should be represented in the string format 'h:mm:ss'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transforming data\n",
      "\n",
      "Age - 0.00%\n",
      "M/F - 0.00%\n",
      "Half - 0.00%\n",
      "Official Time - 0.00%\n",
      "After transforming data\n",
      "\n",
      "Age - 0.0000%\n",
      "M/F - 0.0000%\n",
      "Half - 0.0008%\n",
      "Official Time - 0.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Before transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.2f}%'.format(col,pct_missing))\n",
    "\n",
    "def process_gender(value):\n",
    "    if value in ('M', 'F'):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "\n",
    "def process_age(value):\n",
    "    if (value >=18 and value <=100):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "    \n",
    "def process_time(value):\n",
    "    if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match((value))):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA \n",
    "    \n",
    "\n",
    "df['M/F'] = df['M/F'].apply(process_gender)\n",
    "df['Age'] = df['Age'].apply(process_age)\n",
    "df['Half'] = df['Half'].apply(process_time)\n",
    "df['Official Time'] = df['Official Time'].apply(process_time)\n",
    "\n",
    "print('After transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.4f}%'.format(col,pct_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying transformations to the dataset, which resulted in only a small number of null values, these rows will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Define Transformers</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop a Custom Transformer for age categorization. The input will be an age number, and the output should represent age categories such as '18-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', and '80+'. \n",
    "\n",
    "Additionally, let's define a FunctionTransformer to convert the 'Half marathon time' from the string format 'h:mm:ss' to the numerical feature representing the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].apply(lambda x: pd.cut(x, bins = [0,34,39,44,49,54,59,64,69,74,79,100], labels=['18-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']))\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols\n",
    "\n",
    "class convert_to_seconds(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].applymap(lambda x: pd.to_timedelta(x).total_seconds() if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match(str(x))) else None)\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Preprocessing Pipeline</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a ColumnTransformer, which will be utilized for transforming each column. Within the ColumnTransformer, pipelines are employed to make column transformations flexible and prevent data leakage during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Official Time'],axis=1)\n",
    "\n",
    "enc = convert_to_seconds(input_cols=['Official Time'], output_cols=['Official Time'])\n",
    "Y = enc.transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "preprocessors = ColumnTransformer([\n",
    "    \n",
    "    ('age_pipeline',Pipeline([\n",
    "        ('age_transformed',AgeTransformer(input_cols=['Age'], output_cols=['Age'])),\n",
    "        ('age_encoder',OneHotEncoder(sparse_output = False))       \n",
    "        ]),[\"Age\"]),\n",
    "    \n",
    " \n",
    "    ('gender_pipeline',Pipeline([('gender_encoder',OrdinalEncoder())]), ['M/F']),\n",
    "    \n",
    "    \n",
    "    ('Half_pipeline',Pipeline([\n",
    "        ('time_transformed',convert_to_seconds(input_cols=[\"Half\"], output_cols=[\"Half\"])),   \n",
    "        ('minmax_scaler',MinMaxScaler())     \n",
    "        ]),[\"Half\"])\n",
    "    \n",
    "    ])\n",
    "\n",
    "# X_train_transformed  = preprocessors.fit_transform(X_train)\n",
    "# X_train_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_train_transformed = pd.DataFrame(X_train_transformed, columns = X_train_transformed_names)\n",
    "\n",
    "# X_test_transformed = preprocessors.transform(X_test)\n",
    "# X_test_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_test_transformed = pd.DataFrame(X_test_transformed, columns = X_test_transformed_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">RandomizedSearchCV</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will create pipelines that include a preprocessor and an ML model. These pipelines will be utilized in combination with predefined parameters to evaluate each model using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lasso = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LASSO', Lasso())\n",
    "])\n",
    "\n",
    "pipe_ridge = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RIDGE', Ridge())\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('KNN', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('SVR', SVR())\n",
    "])\n",
    "\n",
    "pipe_et = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ET', ExtraTreesRegressor())\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('DT', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RF', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ADA', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_gbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('GBR', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "pipe_lgbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LGBR', lgb.LGBMRegressor())\n",
    "])\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('CAT', CatBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('XGB', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "lasso_param_grid = [{'LASSO__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "ridge_param_grid = [{'RIDGE__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "\n",
    "knn_param_grid = [{                 \n",
    "                    'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "                    'KNN__weights': ['uniform', 'distance'],\n",
    "                    'KNN__p': [1, 2],             \n",
    "                    }]\n",
    "\n",
    "\n",
    "et_param_grid = [{                 \n",
    "                    'ET__n_estimators': [50, 100, 200],\n",
    "                    'ET__max_depth': [None, 5, 10, 15],\n",
    "                    'ET__min_samples_split': [2, 5, 10],\n",
    "                    'ET__min_samples_leaf': [1, 2, 4],\n",
    "                    'ET__max_features': [1.0, 'sqrt', 'log2']       \n",
    "                    }]\n",
    "\n",
    "dt_param_grid = [{                 \n",
    "                    'DT__max_depth': [None, 5, 10, 15],\n",
    "                    'DT__min_samples_split': [2, 5, 10],\n",
    "                    'DT__min_samples_leaf': [1, 2, 4]          \n",
    "                    }]\n",
    "\n",
    "rf_param_grid = [{                 \n",
    "                    'RF__n_estimators': [50, 100, 200],\n",
    "                    'RF__max_features': [1.0, 'sqrt', 'log2'],\n",
    "                    'RF__max_depth': [None, 10, 20, 30],\n",
    "                    'RF__min_samples_split': [2, 5, 10],\n",
    "                    'RF__min_samples_leaf': [1, 2, 4],\n",
    "                    'RF__bootstrap': [True, False]               \n",
    "                    }]\n",
    "\n",
    "ada_param_grid = [{                 \n",
    "                    'ADA__n_estimators': [50, 100, 200],\n",
    "                    'ADA__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'ADA__loss': ['linear', 'square', 'exponential']            \n",
    "                    }]\n",
    "\n",
    "gbr_param_grid = [{                 \n",
    "                    'GBR__n_estimators': [50, 100, 200],\n",
    "                    'GBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'GBR__max_depth': [3, 5, 7],\n",
    "                    'GBR__subsample': [0.8, 0.9, 1.0]          \n",
    "                    }]\n",
    "\n",
    "lgbr_param_grid = [{                 \n",
    "                    'LGBR__n_estimators': [50, 100, 200],\n",
    "                    'LGBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'LGBR__max_depth': [3, 5, 7],\n",
    "                    'LGBR__subsample': [0.8, 0.9, 1.0],\n",
    "                    'LGBR__colsample_bytree': [0.8, 0.9, 1.0]         \n",
    "                    }]\n",
    "\n",
    "cat_param_grid = [{                 \n",
    "                    'CAT__iterations': [50, 100, 200],\n",
    "                    'CAT__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'CAT__depth': [3, 5, 7],\n",
    "                    'CAT__l2_leaf_reg': [1, 3, 5],\n",
    "                    'CAT__subsample': [0.8, 0.9, 1.0]        \n",
    "                    }]\n",
    "\n",
    "\n",
    "xgb_param_grid = [{                 \n",
    "                    'XGB__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'XGB__n_estimators': [50, 100, 200],\n",
    "                    'XGB__max_depth': [3, 5, 7],\n",
    "                    'XGB__subsample': [0.8, 0.9, 1.0],\n",
    "                    'XGB__colsample_bytree': [0.8, 0.9, 1.0]             \n",
    "                    }]\n",
    "\n",
    "\n",
    "lasso_grid_search = RandomizedSearchCV(estimator=pipe_lasso,\n",
    "        param_distributions=lasso_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ridge_grid_search = RandomizedSearchCV(estimator=pipe_ridge,\n",
    "        param_distributions=ridge_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "knn_grid_search = RandomizedSearchCV(estimator=pipe_knn,\n",
    "        param_distributions=knn_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "et_grid_search = RandomizedSearchCV(estimator=pipe_et,\n",
    "        param_distributions=et_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "dt_grid_search = RandomizedSearchCV(estimator=pipe_dt,\n",
    "        param_distributions=dt_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "rf_grid_search = RandomizedSearchCV(estimator=pipe_rf,\n",
    "        param_distributions=rf_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ada_grid_search = RandomizedSearchCV(estimator=pipe_ada,\n",
    "        param_distributions=ada_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "gbr_grid_search = RandomizedSearchCV(estimator=pipe_gbr,\n",
    "        param_distributions=gbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "lgbr_grid_search = RandomizedSearchCV(estimator=pipe_lgbr,\n",
    "        param_distributions=lgbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "cat_grid_search = RandomizedSearchCV(estimator=pipe_cat,\n",
    "        param_distributions=cat_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "xgb_grid_search = RandomizedSearchCV(estimator=pipe_xgb,\n",
    "        param_distributions=xgb_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Train model and Save results to a text file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RIDGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ET\n",
      "Finished training DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training GBR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LGBR\n",
      "0:\tlearn: 2274.7469139\ttotal: 145ms\tremaining: 28.8s\n",
      "1:\tlearn: 2083.6824713\ttotal: 158ms\tremaining: 15.6s\n",
      "2:\tlearn: 1912.2537392\ttotal: 172ms\tremaining: 11.3s\n",
      "3:\tlearn: 1762.1361044\ttotal: 189ms\tremaining: 9.25s\n",
      "4:\tlearn: 1630.4412310\ttotal: 203ms\tremaining: 7.93s\n",
      "5:\tlearn: 1511.5714915\ttotal: 220ms\tremaining: 7.1s\n",
      "6:\tlearn: 1405.1259155\ttotal: 235ms\tremaining: 6.47s\n",
      "7:\tlearn: 1312.7387157\ttotal: 247ms\tremaining: 5.94s\n",
      "8:\tlearn: 1231.1453798\ttotal: 260ms\tremaining: 5.51s\n",
      "9:\tlearn: 1160.5997614\ttotal: 272ms\tremaining: 5.17s\n",
      "10:\tlearn: 1098.9612692\ttotal: 285ms\tremaining: 4.89s\n",
      "11:\tlearn: 1045.7882746\ttotal: 299ms\tremaining: 4.68s\n",
      "12:\tlearn: 1000.3512011\ttotal: 311ms\tremaining: 4.47s\n",
      "13:\tlearn: 961.0212410\ttotal: 325ms\tremaining: 4.32s\n",
      "14:\tlearn: 927.9821379\ttotal: 337ms\tremaining: 4.16s\n",
      "15:\tlearn: 899.5877207\ttotal: 348ms\tremaining: 4s\n",
      "16:\tlearn: 875.8401284\ttotal: 363ms\tremaining: 3.9s\n",
      "17:\tlearn: 855.8376705\ttotal: 378ms\tremaining: 3.82s\n",
      "18:\tlearn: 838.8059573\ttotal: 391ms\tremaining: 3.72s\n",
      "19:\tlearn: 824.8824063\ttotal: 406ms\tremaining: 3.65s\n",
      "20:\tlearn: 812.5913163\ttotal: 419ms\tremaining: 3.57s\n",
      "21:\tlearn: 802.2020909\ttotal: 433ms\tremaining: 3.51s\n",
      "22:\tlearn: 793.8010364\ttotal: 447ms\tremaining: 3.44s\n",
      "23:\tlearn: 787.0607348\ttotal: 459ms\tremaining: 3.36s\n",
      "24:\tlearn: 781.0655910\ttotal: 473ms\tremaining: 3.31s\n",
      "25:\tlearn: 776.0664183\ttotal: 486ms\tremaining: 3.25s\n",
      "26:\tlearn: 771.7430492\ttotal: 497ms\tremaining: 3.19s\n",
      "27:\tlearn: 768.1916520\ttotal: 507ms\tremaining: 3.11s\n",
      "28:\tlearn: 765.0254521\ttotal: 519ms\tremaining: 3.06s\n",
      "29:\tlearn: 762.5386327\ttotal: 530ms\tremaining: 3s\n",
      "30:\tlearn: 760.4778624\ttotal: 543ms\tremaining: 2.96s\n",
      "31:\tlearn: 758.6731947\ttotal: 554ms\tremaining: 2.91s\n",
      "32:\tlearn: 757.1838138\ttotal: 567ms\tremaining: 2.87s\n",
      "33:\tlearn: 755.6967227\ttotal: 582ms\tremaining: 2.84s\n",
      "34:\tlearn: 754.6574414\ttotal: 595ms\tremaining: 2.81s\n",
      "35:\tlearn: 753.6912145\ttotal: 609ms\tremaining: 2.77s\n",
      "36:\tlearn: 752.8746805\ttotal: 622ms\tremaining: 2.74s\n",
      "37:\tlearn: 752.0446995\ttotal: 634ms\tremaining: 2.7s\n",
      "38:\tlearn: 751.4460528\ttotal: 649ms\tremaining: 2.68s\n",
      "39:\tlearn: 750.9098318\ttotal: 664ms\tremaining: 2.65s\n",
      "40:\tlearn: 750.3659116\ttotal: 678ms\tremaining: 2.63s\n",
      "41:\tlearn: 749.9769769\ttotal: 690ms\tremaining: 2.6s\n",
      "42:\tlearn: 749.5749552\ttotal: 703ms\tremaining: 2.56s\n",
      "43:\tlearn: 749.3738697\ttotal: 713ms\tremaining: 2.53s\n",
      "44:\tlearn: 749.1978803\ttotal: 724ms\tremaining: 2.49s\n",
      "45:\tlearn: 749.0493133\ttotal: 733ms\tremaining: 2.45s\n",
      "46:\tlearn: 748.7958239\ttotal: 745ms\tremaining: 2.42s\n",
      "47:\tlearn: 748.5016482\ttotal: 758ms\tremaining: 2.4s\n",
      "48:\tlearn: 748.2518739\ttotal: 773ms\tremaining: 2.38s\n",
      "49:\tlearn: 748.0923911\ttotal: 785ms\tremaining: 2.35s\n",
      "50:\tlearn: 747.8481021\ttotal: 797ms\tremaining: 2.33s\n",
      "51:\tlearn: 747.6863151\ttotal: 809ms\tremaining: 2.3s\n",
      "52:\tlearn: 747.6481900\ttotal: 815ms\tremaining: 2.26s\n",
      "53:\tlearn: 747.4814478\ttotal: 828ms\tremaining: 2.24s\n",
      "54:\tlearn: 747.3863206\ttotal: 840ms\tremaining: 2.21s\n",
      "55:\tlearn: 747.2335341\ttotal: 851ms\tremaining: 2.19s\n",
      "56:\tlearn: 747.1344876\ttotal: 862ms\tremaining: 2.16s\n",
      "57:\tlearn: 747.0099411\ttotal: 874ms\tremaining: 2.14s\n",
      "58:\tlearn: 746.9635427\ttotal: 885ms\tremaining: 2.11s\n",
      "59:\tlearn: 746.8544937\ttotal: 896ms\tremaining: 2.09s\n",
      "60:\tlearn: 746.7538899\ttotal: 907ms\tremaining: 2.06s\n",
      "61:\tlearn: 746.6946647\ttotal: 915ms\tremaining: 2.04s\n",
      "62:\tlearn: 746.6376970\ttotal: 927ms\tremaining: 2.02s\n",
      "63:\tlearn: 746.5610072\ttotal: 941ms\tremaining: 2s\n",
      "64:\tlearn: 746.5482903\ttotal: 949ms\tremaining: 1.97s\n",
      "65:\tlearn: 746.4688815\ttotal: 960ms\tremaining: 1.95s\n",
      "66:\tlearn: 746.3941612\ttotal: 973ms\tremaining: 1.93s\n",
      "67:\tlearn: 746.3403847\ttotal: 984ms\tremaining: 1.91s\n",
      "68:\tlearn: 746.2840545\ttotal: 996ms\tremaining: 1.89s\n",
      "69:\tlearn: 746.2197699\ttotal: 1.01s\tremaining: 1.87s\n",
      "70:\tlearn: 746.1335470\ttotal: 1.02s\tremaining: 1.85s\n",
      "71:\tlearn: 746.0805918\ttotal: 1.03s\tremaining: 1.83s\n",
      "72:\tlearn: 746.0718358\ttotal: 1.04s\tremaining: 1.8s\n",
      "73:\tlearn: 746.0332887\ttotal: 1.05s\tremaining: 1.78s\n",
      "74:\tlearn: 745.9696789\ttotal: 1.06s\tremaining: 1.76s\n",
      "75:\tlearn: 745.9241511\ttotal: 1.07s\tremaining: 1.74s\n",
      "76:\tlearn: 745.8720875\ttotal: 1.08s\tremaining: 1.73s\n",
      "77:\tlearn: 745.8153034\ttotal: 1.09s\tremaining: 1.71s\n",
      "78:\tlearn: 745.7852864\ttotal: 1.1s\tremaining: 1.69s\n",
      "79:\tlearn: 745.6976846\ttotal: 1.11s\tremaining: 1.67s\n",
      "80:\tlearn: 745.6552978\ttotal: 1.13s\tremaining: 1.66s\n",
      "81:\tlearn: 745.6289060\ttotal: 1.14s\tremaining: 1.64s\n",
      "82:\tlearn: 745.5774964\ttotal: 1.15s\tremaining: 1.62s\n",
      "83:\tlearn: 745.5467606\ttotal: 1.16s\tremaining: 1.6s\n",
      "84:\tlearn: 745.5424942\ttotal: 1.17s\tremaining: 1.58s\n",
      "85:\tlearn: 745.5012715\ttotal: 1.18s\tremaining: 1.56s\n",
      "86:\tlearn: 745.4876762\ttotal: 1.19s\tremaining: 1.54s\n",
      "87:\tlearn: 745.4678423\ttotal: 1.2s\tremaining: 1.53s\n",
      "88:\tlearn: 745.4373002\ttotal: 1.21s\tremaining: 1.51s\n",
      "89:\tlearn: 745.3836059\ttotal: 1.22s\tremaining: 1.49s\n",
      "90:\tlearn: 745.3311623\ttotal: 1.23s\tremaining: 1.47s\n",
      "91:\tlearn: 745.2815264\ttotal: 1.24s\tremaining: 1.46s\n",
      "92:\tlearn: 745.2389579\ttotal: 1.25s\tremaining: 1.44s\n",
      "93:\tlearn: 745.1695109\ttotal: 1.26s\tremaining: 1.43s\n",
      "94:\tlearn: 745.1672679\ttotal: 1.27s\tremaining: 1.4s\n",
      "95:\tlearn: 745.1192980\ttotal: 1.28s\tremaining: 1.39s\n",
      "96:\tlearn: 745.0848051\ttotal: 1.29s\tremaining: 1.37s\n",
      "97:\tlearn: 745.0634486\ttotal: 1.3s\tremaining: 1.35s\n",
      "98:\tlearn: 745.0118861\ttotal: 1.31s\tremaining: 1.34s\n",
      "99:\tlearn: 744.9541323\ttotal: 1.32s\tremaining: 1.32s\n",
      "100:\tlearn: 744.9181985\ttotal: 1.33s\tremaining: 1.31s\n",
      "101:\tlearn: 744.8791729\ttotal: 1.35s\tremaining: 1.29s\n",
      "102:\tlearn: 744.8273573\ttotal: 1.36s\tremaining: 1.28s\n",
      "103:\tlearn: 744.7915614\ttotal: 1.37s\tremaining: 1.27s\n",
      "104:\tlearn: 744.7591618\ttotal: 1.38s\tremaining: 1.25s\n",
      "105:\tlearn: 744.7086134\ttotal: 1.39s\tremaining: 1.24s\n",
      "106:\tlearn: 744.6776113\ttotal: 1.4s\tremaining: 1.22s\n",
      "107:\tlearn: 744.6288065\ttotal: 1.41s\tremaining: 1.2s\n",
      "108:\tlearn: 744.6049748\ttotal: 1.42s\tremaining: 1.19s\n",
      "109:\tlearn: 744.6021463\ttotal: 1.43s\tremaining: 1.17s\n",
      "110:\tlearn: 744.5750225\ttotal: 1.44s\tremaining: 1.16s\n",
      "111:\tlearn: 744.5458742\ttotal: 1.45s\tremaining: 1.14s\n",
      "112:\tlearn: 744.5233608\ttotal: 1.46s\tremaining: 1.13s\n",
      "113:\tlearn: 744.4378180\ttotal: 1.47s\tremaining: 1.11s\n",
      "114:\tlearn: 744.4133550\ttotal: 1.48s\tremaining: 1.1s\n",
      "115:\tlearn: 744.3314619\ttotal: 1.5s\tremaining: 1.08s\n",
      "116:\tlearn: 744.3024334\ttotal: 1.5s\tremaining: 1.07s\n",
      "117:\tlearn: 744.2557641\ttotal: 1.52s\tremaining: 1.05s\n",
      "118:\tlearn: 744.2239333\ttotal: 1.53s\tremaining: 1.04s\n",
      "119:\tlearn: 744.1638752\ttotal: 1.54s\tremaining: 1.02s\n",
      "120:\tlearn: 744.0933764\ttotal: 1.55s\tremaining: 1.01s\n",
      "121:\tlearn: 744.0421629\ttotal: 1.56s\tremaining: 999ms\n",
      "122:\tlearn: 744.0033276\ttotal: 1.57s\tremaining: 986ms\n",
      "123:\tlearn: 743.9646474\ttotal: 1.58s\tremaining: 971ms\n",
      "124:\tlearn: 743.9227042\ttotal: 1.6s\tremaining: 959ms\n",
      "125:\tlearn: 743.8800285\ttotal: 1.61s\tremaining: 945ms\n",
      "126:\tlearn: 743.8136997\ttotal: 1.62s\tremaining: 930ms\n",
      "127:\tlearn: 743.7544976\ttotal: 1.63s\tremaining: 917ms\n",
      "128:\tlearn: 743.7137284\ttotal: 1.64s\tremaining: 903ms\n",
      "129:\tlearn: 743.6787492\ttotal: 1.65s\tremaining: 889ms\n",
      "130:\tlearn: 743.6512046\ttotal: 1.66s\tremaining: 876ms\n",
      "131:\tlearn: 743.6190856\ttotal: 1.67s\tremaining: 862ms\n",
      "132:\tlearn: 743.5779163\ttotal: 1.69s\tremaining: 849ms\n",
      "133:\tlearn: 743.5439534\ttotal: 1.7s\tremaining: 836ms\n",
      "134:\tlearn: 743.5061054\ttotal: 1.71s\tremaining: 822ms\n",
      "135:\tlearn: 743.4733837\ttotal: 1.72s\tremaining: 810ms\n",
      "136:\tlearn: 743.4332552\ttotal: 1.73s\tremaining: 797ms\n",
      "137:\tlearn: 743.3851660\ttotal: 1.74s\tremaining: 784ms\n",
      "138:\tlearn: 743.3581443\ttotal: 1.76s\tremaining: 771ms\n",
      "139:\tlearn: 743.3231622\ttotal: 1.77s\tremaining: 758ms\n",
      "140:\tlearn: 743.2922720\ttotal: 1.78s\tremaining: 745ms\n",
      "141:\tlearn: 743.2766049\ttotal: 1.79s\tremaining: 731ms\n",
      "142:\tlearn: 743.2456330\ttotal: 1.8s\tremaining: 719ms\n",
      "143:\tlearn: 743.2097820\ttotal: 1.81s\tremaining: 705ms\n",
      "144:\tlearn: 743.1694802\ttotal: 1.82s\tremaining: 692ms\n",
      "145:\tlearn: 743.1357057\ttotal: 1.83s\tremaining: 678ms\n",
      "146:\tlearn: 743.0986708\ttotal: 1.85s\tremaining: 666ms\n",
      "147:\tlearn: 743.0819756\ttotal: 1.86s\tremaining: 653ms\n",
      "148:\tlearn: 743.0470194\ttotal: 1.87s\tremaining: 640ms\n",
      "149:\tlearn: 743.0163303\ttotal: 1.88s\tremaining: 627ms\n",
      "150:\tlearn: 743.0016895\ttotal: 1.89s\tremaining: 614ms\n",
      "151:\tlearn: 742.9677391\ttotal: 1.9s\tremaining: 601ms\n",
      "152:\tlearn: 742.9383998\ttotal: 1.91s\tremaining: 588ms\n",
      "153:\tlearn: 742.9190911\ttotal: 1.93s\tremaining: 576ms\n",
      "154:\tlearn: 742.8872523\ttotal: 1.94s\tremaining: 563ms\n",
      "155:\tlearn: 742.8675688\ttotal: 1.95s\tremaining: 551ms\n",
      "156:\tlearn: 742.8109813\ttotal: 1.97s\tremaining: 538ms\n",
      "157:\tlearn: 742.7876068\ttotal: 1.98s\tremaining: 526ms\n",
      "158:\tlearn: 742.7771605\ttotal: 1.99s\tremaining: 513ms\n",
      "159:\tlearn: 742.7515968\ttotal: 2s\tremaining: 500ms\n",
      "160:\tlearn: 742.7237482\ttotal: 2.01s\tremaining: 487ms\n",
      "161:\tlearn: 742.6957817\ttotal: 2.02s\tremaining: 474ms\n",
      "162:\tlearn: 742.6753800\ttotal: 2.03s\tremaining: 461ms\n",
      "163:\tlearn: 742.6431024\ttotal: 2.04s\tremaining: 448ms\n",
      "164:\tlearn: 742.6338919\ttotal: 2.05s\tremaining: 436ms\n",
      "165:\tlearn: 742.5887770\ttotal: 2.07s\tremaining: 423ms\n",
      "166:\tlearn: 742.5711293\ttotal: 2.08s\tremaining: 410ms\n",
      "167:\tlearn: 742.5594497\ttotal: 2.09s\tremaining: 398ms\n",
      "168:\tlearn: 742.5366331\ttotal: 2.1s\tremaining: 385ms\n",
      "169:\tlearn: 742.5307339\ttotal: 2.11s\tremaining: 372ms\n",
      "170:\tlearn: 742.5013281\ttotal: 2.12s\tremaining: 360ms\n",
      "171:\tlearn: 742.4698781\ttotal: 2.13s\tremaining: 348ms\n",
      "172:\tlearn: 742.4172459\ttotal: 2.15s\tremaining: 335ms\n",
      "173:\tlearn: 742.3861573\ttotal: 2.16s\tremaining: 323ms\n",
      "174:\tlearn: 742.3435496\ttotal: 2.17s\tremaining: 310ms\n",
      "175:\tlearn: 742.3176382\ttotal: 2.18s\tremaining: 298ms\n",
      "176:\tlearn: 742.2836410\ttotal: 2.19s\tremaining: 285ms\n",
      "177:\tlearn: 742.2773703\ttotal: 2.21s\tremaining: 273ms\n",
      "178:\tlearn: 742.2500600\ttotal: 2.22s\tremaining: 260ms\n",
      "179:\tlearn: 742.2214801\ttotal: 2.23s\tremaining: 248ms\n",
      "180:\tlearn: 742.1824296\ttotal: 2.24s\tremaining: 235ms\n",
      "181:\tlearn: 742.1770731\ttotal: 2.25s\tremaining: 223ms\n",
      "182:\tlearn: 742.1493759\ttotal: 2.26s\tremaining: 210ms\n",
      "183:\tlearn: 742.1442636\ttotal: 2.27s\tremaining: 198ms\n",
      "184:\tlearn: 742.1212290\ttotal: 2.28s\tremaining: 185ms\n",
      "185:\tlearn: 742.0937711\ttotal: 2.29s\tremaining: 173ms\n",
      "186:\tlearn: 742.0815332\ttotal: 2.3s\tremaining: 160ms\n",
      "187:\tlearn: 742.0585669\ttotal: 2.31s\tremaining: 148ms\n",
      "188:\tlearn: 742.0332072\ttotal: 2.33s\tremaining: 135ms\n",
      "189:\tlearn: 742.0154324\ttotal: 2.34s\tremaining: 123ms\n",
      "190:\tlearn: 741.9964975\ttotal: 2.35s\tremaining: 111ms\n",
      "191:\tlearn: 741.9592040\ttotal: 2.36s\tremaining: 98.4ms\n",
      "192:\tlearn: 741.9369654\ttotal: 2.37s\tremaining: 86.1ms\n",
      "193:\tlearn: 741.8997752\ttotal: 2.38s\tremaining: 73.8ms\n",
      "194:\tlearn: 741.8833312\ttotal: 2.4s\tremaining: 61.5ms\n",
      "195:\tlearn: 741.8706845\ttotal: 2.41s\tremaining: 49.1ms\n",
      "196:\tlearn: 741.8398400\ttotal: 2.42s\tremaining: 36.8ms\n",
      "197:\tlearn: 741.8082780\ttotal: 2.43s\tremaining: 24.5ms\n",
      "198:\tlearn: 741.7902308\ttotal: 2.44s\tremaining: 12.2ms\n",
      "199:\tlearn: 741.7651262\ttotal: 2.45s\tremaining: 0us\n",
      "Finished training CAT\n",
      "Finished training XGB\n"
     ]
    }
   ],
   "source": [
    "grids = [lasso_grid_search,\n",
    "         ridge_grid_search,\n",
    "         knn_grid_search,\n",
    "         et_grid_search,\n",
    "         dt_grid_search,\n",
    "         rf_grid_search,\n",
    "         ada_grid_search,\n",
    "         gbr_grid_search,\n",
    "         lgbr_grid_search,\n",
    "         cat_grid_search,\n",
    "         xgb_grid_search\n",
    "         ]\n",
    "\n",
    "for pipe in grids:\n",
    "    pipe.fit(X_train,y_train)\n",
    "    print('Finished training {}'.format(pipe.estimator.steps[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will save results of the training and model evaluations will in txt and csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso Test metric: -531.7665231997508\n",
      "lasso Best Params: {'LASSO__alpha': 0.01}\n",
      "ridge Test metric: -531.7719592638392\n",
      "ridge Best Params: {'RIDGE__alpha': 1e-15}\n",
      "knn Test metric: -557.286765630897\n",
      "knn Best Params: {'KNN__weights': 'uniform', 'KNN__p': 1, 'KNN__n_neighbors': 9}\n",
      "et Test metric: -529.99412142352\n",
      "et Best Params: {'ET__n_estimators': 200, 'ET__min_samples_split': 10, 'ET__min_samples_leaf': 1, 'ET__max_features': 1.0, 'ET__max_depth': 10}\n",
      "dt Test metric: -536.5410483749902\n",
      "dt Best Params: {'DT__min_samples_split': 5, 'DT__min_samples_leaf': 4, 'DT__max_depth': 10}\n",
      "rf Test metric: -530.1034899336967\n",
      "rf Best Params: {'RF__n_estimators': 200, 'RF__min_samples_split': 5, 'RF__min_samples_leaf': 1, 'RF__max_features': 1.0, 'RF__max_depth': 10, 'RF__bootstrap': True}\n",
      "ada Test metric: -604.702823321766\n",
      "ada Best Params: {'ADA__n_estimators': 200, 'ADA__loss': 'exponential', 'ADA__learning_rate': 0.01}\n",
      "gbr Test metric: -526.7273375179053\n",
      "gbr Best Params: {'GBR__subsample': 0.8, 'GBR__n_estimators': 100, 'GBR__max_depth': 5, 'GBR__learning_rate': 0.1}\n",
      "lgbr Test metric: -528.4288903500549\n",
      "lgbr Best Params: {'LGBR__subsample': 1.0, 'LGBR__n_estimators': 200, 'LGBR__max_depth': 5, 'LGBR__learning_rate': 0.1, 'LGBR__colsample_bytree': 0.9}\n",
      "cat Test metric: -527.5703362153196\n",
      "cat Best Params: {'CAT__subsample': 1.0, 'CAT__learning_rate': 0.1, 'CAT__l2_leaf_reg': 5, 'CAT__iterations': 200, 'CAT__depth': 7}\n",
      "xgb Test metric: -516.6271392480579\n",
      "xgb Best Params: {'XGB__subsample': 1.0, 'XGB__n_estimators': 50, 'XGB__max_depth': 5, 'XGB__learning_rate': 0.1, 'XGB__colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "grid_dict = {\n",
    "                0: 'lasso',\n",
    "                1: 'ridge',\n",
    "                2: 'knn',\n",
    "                3: 'et',\n",
    "                4: 'dt',\n",
    "                5: 'rf',\n",
    "                6: 'ada',\n",
    "                7: 'gbr',\n",
    "                8: 'lgbr',\n",
    "                9:'cat',\n",
    "                10:'xgb'\n",
    "                }\n",
    "\n",
    "results = []\n",
    "for i, model in enumerate(grids):\n",
    "    print('{} Test metric: {}'.format(grid_dict[i],\n",
    "    model.score(X_test,y_test)))\n",
    "    print('{} Best Params: {}'.format(grid_dict[i], model.best_params_))\n",
    "    y_true, y_pred = y_test, model.best_estimator_.predict(X_test),\n",
    "    \n",
    "    results.append({    \n",
    "        'iterator': i,\n",
    "        'model': grid_dict[i],\n",
    "        'best_params': model.best_params_,\n",
    "        'best_score': model.best_score_,\n",
    "        'mae': mean_absolute_error(y_true,y_pred),\n",
    "        'mse': mean_squared_error(y_true,y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true,y_pred)),\n",
    "        'r2': r2_score(y_true,y_pred)\n",
    "        })\n",
    "    \n",
    "results = sorted(results, key=itemgetter('best_score'), reverse=True) \n",
    "\n",
    " \n",
    "with open('results/half_grid_search_results.txt', 'w') as file:\n",
    "    for result in results:\n",
    "        file.write(f\"Model: {result['model']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(\"Best Parameters:\\n\")\n",
    "        for key, value in result['best_params'].items():\n",
    "            file.write(f\"{key}: {value}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(f\"Best Score: {result['best_score']}\\n\")\n",
    "        file.write(f\"mae: {result['mae']}\\n\")\n",
    "        file.write(f\"mse: {result['mse']}\\n\")\n",
    "        file.write(f\"rmse: {result['rmse']}\\n\")\n",
    "        file.write(f\"r2: {result['r2']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "models_scores = pd.DataFrame(results)\n",
    "models_scores = models_scores[['model','mae','mse','rmse','r2']]\n",
    "models_scores.to_csv('results/half_models_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how did models performed on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model         mae            mse        rmse        r2\n",
      "0     xgb  516.627139  599484.150848  774.263618  0.904406\n",
      "1     gbr  526.727338  596046.065145  772.040197  0.904955\n",
      "2     cat  527.570336  596587.159134  772.390548  0.904868\n",
      "3      et  529.994121  597236.991706  772.811097  0.904765\n",
      "4    lgbr  528.428890  596961.232139  772.632663  0.904809\n",
      "5   lasso  531.766523  605627.359783  778.220637  0.903427\n",
      "6   ridge  531.771959  605639.790312  778.228623  0.903425\n",
      "7      rf  530.103490  603650.743532  776.949640  0.903742\n",
      "8      dt  536.541048  616516.243404  785.185483  0.901690\n",
      "9     knn  557.286766  652421.414178  807.726076  0.895965\n",
      "10    ada  604.702823  716863.473542  846.677904  0.885689\n"
     ]
    }
   ],
   "source": [
    "print(models_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it appears that all models are performing well. We can observe R2 values within the range of 0.88-0.90 (using 5K time it was 0.77-0.80), and MAE falls between 516-604 (using 5K time it was 819-882 seconds), which is satisfactory given that we are attempting to predict marathon finish time based on age, gender, and half marathon race time. It is evident that the model trained with half marathon race times provides even better predictions than models trained with 5 km and 10 km race times, as anticipated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Saving best model and making prediction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best model XGB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/half_best_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = grids[results[0]['iterator']]\n",
    "print('Found best model {}'.format(best_model.estimator.steps[-1][0]))\n",
    "\n",
    "joblib.dump(best_model, 'models/half_best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and making predictions for myself! 😁 (Even though I can typically run half marathon faster, this would be my expected time during longer runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My predicted marathon time in hh:mm:ss is: 3:46:36\n",
      "My predicted marathon time in hh:mm:ss is: 3:39:36\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "best_model_loaded = joblib.load(\"models/half_best_model.pkl\") \n",
    "\n",
    "# Testing mysef\n",
    "d = {'Age': [30], 'M/F': ['M'], 'Half': ['1:45:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))\n",
    "\n",
    "# Testing mysef as female\n",
    "d = {'Age': [30], 'M/F': ['F'], 'Half': ['1:45:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current predictions from the model are quite accurate, especially considering that my best marathon time is around 3:40:00. Additionally, an interesting observation is that changing the gender from male to female seems to improve the predicted outcomes. This aligns with known information on the subject, as explored in the Exploratory Data Analysis (EDA) notebook, suggesting that females generally exhibit better endurance than males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A machine learning model has been successfully developed for predicting marathon finish times, leveraging features such as age, gender, and half marathon race time. The results demonstrate the model's effectiveness. As demonstrated in this notebook, models trained with half marathon race times exhibited better performance compared to models trained using 5 km or 10 km race times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
