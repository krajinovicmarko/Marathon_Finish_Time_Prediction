{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Machine Learning Marathon finish time estimation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to create a machine learning model for predicting marathon finish times based on age, gender, and 5 km race time running at a marathon pace. Additional models will be developed to make predictions using 10 km or 21 km race times. The model is designed for runners who are already capable of completing a full marathon, as it will be trained on data from runners who have successfully finished the entire marathon distance. This predictive tool can be valuable for individuals preparing for a marathon, providing an estimate of their potential marathon finish time. This is particularly useful since many marathoners typically do not run more than 32-35 km during their training for a marathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from operator import itemgetter\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,RobustScaler,MinMaxScaler,OrdinalEncoder,FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Read the Dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load data on finishers from the Boston Marathon for the years of 2015, 2016 and 2017. Dataset can be accessed via this link [Boston dataset](https://www.kaggle.com/datasets/rojour/boston-results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, glob.glob('dataset/*.csv')))\n",
    "df = df[['Age','M/F','5K','Official Time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Clean data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data by removing unwanted or empty values. For the 'Gender' attribute, only 'M' or 'F' values are allowed. The 'Age' should be any number between 18 and 100. The '5K time' should be represented in the string format 'h:mm:ss'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transforming data\n",
      "\n",
      "Age - 0.00%\n",
      "M/F - 0.00%\n",
      "5K - 0.00%\n",
      "Official Time - 0.00%\n",
      "After transforming data\n",
      "\n",
      "Age - 0.0000%\n",
      "M/F - 0.0000%\n",
      "5K - 0.0029%\n",
      "Official Time - 0.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Before transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.2f}%'.format(col,pct_missing))\n",
    "\n",
    "def process_gender(value):\n",
    "    if value in ('M', 'F'):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "\n",
    "def process_age(value):\n",
    "    if (value >=18 and value <=100):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA  \n",
    "    \n",
    "def process_time(value):\n",
    "    if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match((value))):\n",
    "        return value\n",
    "    else:\n",
    "        return pd.NA \n",
    "    \n",
    "\n",
    "df['M/F'] = df['M/F'].apply(process_gender)\n",
    "df['Age'] = df['Age'].apply(process_age)\n",
    "df['5K'] = df['5K'].apply(process_time)\n",
    "df['Official Time'] = df['Official Time'].apply(process_time)\n",
    "\n",
    "print('After transforming data\\n')\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {:.4f}%'.format(col,pct_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying transformations to the dataset, which resulted in only a small number of null values, these rows will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Define Transformers</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop a Custom Transformer for age categorization. The input will be an age number, and the output should represent age categories such as '18-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', and '80+'. \n",
    "\n",
    "Additionally, let's define a FunctionTransformer to convert the '5K time' from the string format 'h:mm:ss' to the numerical feature representing the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].apply(lambda x: pd.cut(x, bins = [0,34,39,44,49,54,59,64,69,74,79,100], labels=['18-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','75-79','80+']))\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols\n",
    "\n",
    "class convert_to_seconds(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, input_cols, output_cols):\n",
    "        self.input_cols = input_cols\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.input_cols].applymap(lambda x: pd.to_timedelta(x).total_seconds() if bool(re.compile(r'^(\\d):([0-5]\\d):([0-5]\\d)$').match(str(x))) else None)\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names):\n",
    "        return self.output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Preprocessing Pipeline</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a ColumnTransformer, which will be utilized for transforming each column. Within the ColumnTransformer, pipelines are employed to make column transformations flexible and prevent data leakage during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Official Time'],axis=1)\n",
    "\n",
    "enc = convert_to_seconds(input_cols=['Official Time'], output_cols=['Official Time'])\n",
    "Y = enc.transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "preprocessors = ColumnTransformer([\n",
    "    \n",
    "    ('age_pipeline',Pipeline([\n",
    "        ('age_transformed',AgeTransformer(input_cols=['Age'], output_cols=['Age'])),\n",
    "        ('age_encoder',OneHotEncoder(sparse_output = False))       \n",
    "        ]),[\"Age\"]),\n",
    "    \n",
    " \n",
    "    ('gender_pipeline',Pipeline([('gender_encoder',OrdinalEncoder())]), ['M/F']),\n",
    "    \n",
    "    \n",
    "    ('5K_pipeline',Pipeline([\n",
    "        ('time_transformed',convert_to_seconds(input_cols=[\"5K\"], output_cols=[\"5K\"])),   \n",
    "        ('minmax_scaler',MinMaxScaler())     \n",
    "        ]),[\"5K\"])\n",
    "    \n",
    "    ])\n",
    "\n",
    "# X_train_transformed  = preprocessors.fit_transform(X_train)\n",
    "# X_train_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_train_transformed = pd.DataFrame(X_train_transformed, columns = X_train_transformed_names)\n",
    "\n",
    "# X_test_transformed = preprocessors.transform(X_test)\n",
    "# X_test_transformed_names = preprocessors.get_feature_names_out()\n",
    "# X_test_transformed = pd.DataFrame(X_test_transformed, columns = X_test_transformed_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">RandomizedSearchCV</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will create pipelines that include a preprocessor and an ML model. These pipelines will be utilized in combination with predefined parameters to evaluate each model using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lasso = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LASSO', Lasso())\n",
    "])\n",
    "\n",
    "pipe_ridge = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RIDGE', Ridge())\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('KNN', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('SVR', SVR())\n",
    "])\n",
    "\n",
    "pipe_et = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ET', ExtraTreesRegressor())\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('DT', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('RF', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('ADA', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_gbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('GBR', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "pipe_lgbr = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('LGBR', lgb.LGBMRegressor())\n",
    "])\n",
    "\n",
    "pipe_cat = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('CAT', CatBoostRegressor())\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "   \n",
    "    ('preprocessors', preprocessors),\n",
    "    ('XGB', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "lasso_param_grid = [{'LASSO__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "ridge_param_grid = [{'RIDGE__alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,55,100]\n",
    "                \n",
    "                    }]\n",
    "\n",
    "\n",
    "knn_param_grid = [{                 \n",
    "                    'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "                    'KNN__weights': ['uniform', 'distance'],\n",
    "                    'KNN__p': [1, 2],             \n",
    "                    }]\n",
    "\n",
    "\n",
    "et_param_grid = [{                 \n",
    "                    'ET__n_estimators': [50, 100, 200],\n",
    "                    'ET__max_depth': [None, 5, 10, 15],\n",
    "                    'ET__min_samples_split': [2, 5, 10],\n",
    "                    'ET__min_samples_leaf': [1, 2, 4],\n",
    "                    'ET__max_features': [1.0, 'sqrt', 'log2']       \n",
    "                    }]\n",
    "\n",
    "dt_param_grid = [{                 \n",
    "                    'DT__max_depth': [None, 5, 10, 15],\n",
    "                    'DT__min_samples_split': [2, 5, 10],\n",
    "                    'DT__min_samples_leaf': [1, 2, 4]          \n",
    "                    }]\n",
    "\n",
    "rf_param_grid = [{                 \n",
    "                    'RF__n_estimators': [50, 100, 200],\n",
    "                    'RF__max_features': [1.0, 'sqrt', 'log2'],\n",
    "                    'RF__max_depth': [None, 10, 20, 30],\n",
    "                    'RF__min_samples_split': [2, 5, 10],\n",
    "                    'RF__min_samples_leaf': [1, 2, 4],\n",
    "                    'RF__bootstrap': [True, False]               \n",
    "                    }]\n",
    "\n",
    "ada_param_grid = [{                 \n",
    "                    'ADA__n_estimators': [50, 100, 200],\n",
    "                    'ADA__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'ADA__loss': ['linear', 'square', 'exponential']            \n",
    "                    }]\n",
    "\n",
    "gbr_param_grid = [{                 \n",
    "                    'GBR__n_estimators': [50, 100, 200],\n",
    "                    'GBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'GBR__max_depth': [3, 5, 7],\n",
    "                    'GBR__subsample': [0.8, 0.9, 1.0]          \n",
    "                    }]\n",
    "\n",
    "lgbr_param_grid = [{                 \n",
    "                    'LGBR__n_estimators': [50, 100, 200],\n",
    "                    'LGBR__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'LGBR__max_depth': [3, 5, 7],\n",
    "                    'LGBR__subsample': [0.8, 0.9, 1.0],\n",
    "                    'LGBR__colsample_bytree': [0.8, 0.9, 1.0]         \n",
    "                    }]\n",
    "\n",
    "cat_param_grid = [{                 \n",
    "                    'CAT__iterations': [50, 100, 200],\n",
    "                    'CAT__learning_rate': [0.01, 0.1, 1.0],\n",
    "                    'CAT__depth': [3, 5, 7],\n",
    "                    'CAT__l2_leaf_reg': [1, 3, 5],\n",
    "                    'CAT__subsample': [0.8, 0.9, 1.0]        \n",
    "                    }]\n",
    "\n",
    "\n",
    "xgb_param_grid = [{                 \n",
    "                    'XGB__learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'XGB__n_estimators': [50, 100, 200],\n",
    "                    'XGB__max_depth': [3, 5, 7],\n",
    "                    'XGB__subsample': [0.8, 0.9, 1.0],\n",
    "                    'XGB__colsample_bytree': [0.8, 0.9, 1.0]             \n",
    "                    }]\n",
    "\n",
    "\n",
    "lasso_grid_search = RandomizedSearchCV(estimator=pipe_lasso,\n",
    "        param_distributions=lasso_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ridge_grid_search = RandomizedSearchCV(estimator=pipe_ridge,\n",
    "        param_distributions=ridge_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "knn_grid_search = RandomizedSearchCV(estimator=pipe_knn,\n",
    "        param_distributions=knn_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "et_grid_search = RandomizedSearchCV(estimator=pipe_et,\n",
    "        param_distributions=et_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "dt_grid_search = RandomizedSearchCV(estimator=pipe_dt,\n",
    "        param_distributions=dt_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "rf_grid_search = RandomizedSearchCV(estimator=pipe_rf,\n",
    "        param_distributions=rf_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "ada_grid_search = RandomizedSearchCV(estimator=pipe_ada,\n",
    "        param_distributions=ada_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "gbr_grid_search = RandomizedSearchCV(estimator=pipe_gbr,\n",
    "        param_distributions=gbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "lgbr_grid_search = RandomizedSearchCV(estimator=pipe_lgbr,\n",
    "        param_distributions=lgbr_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "cat_grid_search = RandomizedSearchCV(estimator=pipe_cat,\n",
    "        param_distributions=cat_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)\n",
    "\n",
    "xgb_grid_search = RandomizedSearchCV(estimator=pipe_xgb,\n",
    "        param_distributions=xgb_param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,n_iter=20,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Train model and Save results to a text file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+10, tolerance: 3.928e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.08514e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RIDGE\n",
      "Finished training KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ET\n",
      "Finished training DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training ADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training GBR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LGBR\n",
      "0:\tlearn: 2304.5035067\ttotal: 156ms\tremaining: 15.4s\n",
      "1:\tlearn: 2144.0675449\ttotal: 169ms\tremaining: 8.27s\n",
      "2:\tlearn: 2001.0008833\ttotal: 181ms\tremaining: 5.87s\n",
      "3:\tlearn: 1877.9487580\ttotal: 195ms\tremaining: 4.68s\n",
      "4:\tlearn: 1769.9191719\ttotal: 208ms\tremaining: 3.95s\n",
      "5:\tlearn: 1674.8033334\ttotal: 221ms\tremaining: 3.47s\n",
      "6:\tlearn: 1593.0412935\ttotal: 234ms\tremaining: 3.1s\n",
      "7:\tlearn: 1523.4069669\ttotal: 246ms\tremaining: 2.83s\n",
      "8:\tlearn: 1462.8484155\ttotal: 259ms\tremaining: 2.62s\n",
      "9:\tlearn: 1412.3252407\ttotal: 271ms\tremaining: 2.44s\n",
      "10:\tlearn: 1368.5351587\ttotal: 283ms\tremaining: 2.29s\n",
      "11:\tlearn: 1331.0079804\ttotal: 295ms\tremaining: 2.17s\n",
      "12:\tlearn: 1300.6577880\ttotal: 307ms\tremaining: 2.06s\n",
      "13:\tlearn: 1274.4904589\ttotal: 320ms\tremaining: 1.97s\n",
      "14:\tlearn: 1252.8140242\ttotal: 334ms\tremaining: 1.89s\n",
      "15:\tlearn: 1235.1547046\ttotal: 347ms\tremaining: 1.82s\n",
      "16:\tlearn: 1219.8140786\ttotal: 359ms\tremaining: 1.75s\n",
      "17:\tlearn: 1206.9582958\ttotal: 374ms\tremaining: 1.7s\n",
      "18:\tlearn: 1196.3503090\ttotal: 387ms\tremaining: 1.65s\n",
      "19:\tlearn: 1187.2328770\ttotal: 399ms\tremaining: 1.59s\n",
      "20:\tlearn: 1179.7459527\ttotal: 411ms\tremaining: 1.54s\n",
      "21:\tlearn: 1173.4168020\ttotal: 422ms\tremaining: 1.5s\n",
      "22:\tlearn: 1168.1589332\ttotal: 433ms\tremaining: 1.45s\n",
      "23:\tlearn: 1163.4720069\ttotal: 446ms\tremaining: 1.41s\n",
      "24:\tlearn: 1159.7416904\ttotal: 458ms\tremaining: 1.38s\n",
      "25:\tlearn: 1156.2737630\ttotal: 470ms\tremaining: 1.34s\n",
      "26:\tlearn: 1153.6449357\ttotal: 482ms\tremaining: 1.3s\n",
      "27:\tlearn: 1151.2527473\ttotal: 494ms\tremaining: 1.27s\n",
      "28:\tlearn: 1149.3837832\ttotal: 506ms\tremaining: 1.24s\n",
      "29:\tlearn: 1147.7015958\ttotal: 518ms\tremaining: 1.21s\n",
      "30:\tlearn: 1146.2441259\ttotal: 529ms\tremaining: 1.18s\n",
      "31:\tlearn: 1145.0903698\ttotal: 541ms\tremaining: 1.15s\n",
      "32:\tlearn: 1144.1189845\ttotal: 553ms\tremaining: 1.12s\n",
      "33:\tlearn: 1143.1012729\ttotal: 565ms\tremaining: 1.09s\n",
      "34:\tlearn: 1142.0849906\ttotal: 577ms\tremaining: 1.07s\n",
      "35:\tlearn: 1141.4419299\ttotal: 589ms\tremaining: 1.05s\n",
      "36:\tlearn: 1140.8267094\ttotal: 604ms\tremaining: 1.03s\n",
      "37:\tlearn: 1140.2619669\ttotal: 616ms\tremaining: 1s\n",
      "38:\tlearn: 1139.7617877\ttotal: 628ms\tremaining: 982ms\n",
      "39:\tlearn: 1139.2372223\ttotal: 638ms\tremaining: 958ms\n",
      "40:\tlearn: 1138.6909185\ttotal: 650ms\tremaining: 936ms\n",
      "41:\tlearn: 1138.2580888\ttotal: 662ms\tremaining: 914ms\n",
      "42:\tlearn: 1137.8881788\ttotal: 672ms\tremaining: 891ms\n",
      "43:\tlearn: 1137.6081425\ttotal: 684ms\tremaining: 870ms\n",
      "44:\tlearn: 1137.3288081\ttotal: 695ms\tremaining: 849ms\n",
      "45:\tlearn: 1137.1419733\ttotal: 706ms\tremaining: 828ms\n",
      "46:\tlearn: 1137.0603343\ttotal: 713ms\tremaining: 804ms\n",
      "47:\tlearn: 1136.8647953\ttotal: 724ms\tremaining: 784ms\n",
      "48:\tlearn: 1136.7165308\ttotal: 735ms\tremaining: 765ms\n",
      "49:\tlearn: 1136.6380979\ttotal: 743ms\tremaining: 743ms\n",
      "50:\tlearn: 1136.5239473\ttotal: 752ms\tremaining: 722ms\n",
      "51:\tlearn: 1136.4330973\ttotal: 762ms\tremaining: 703ms\n",
      "52:\tlearn: 1136.3059921\ttotal: 773ms\tremaining: 685ms\n",
      "53:\tlearn: 1136.2005480\ttotal: 785ms\tremaining: 668ms\n",
      "54:\tlearn: 1136.1497380\ttotal: 793ms\tremaining: 649ms\n",
      "55:\tlearn: 1136.0079211\ttotal: 805ms\tremaining: 633ms\n",
      "56:\tlearn: 1135.8338589\ttotal: 816ms\tremaining: 615ms\n",
      "57:\tlearn: 1135.7861658\ttotal: 826ms\tremaining: 598ms\n",
      "58:\tlearn: 1135.6526587\ttotal: 837ms\tremaining: 582ms\n",
      "59:\tlearn: 1135.5350392\ttotal: 848ms\tremaining: 565ms\n",
      "60:\tlearn: 1135.4455958\ttotal: 858ms\tremaining: 549ms\n",
      "61:\tlearn: 1135.3724207\ttotal: 870ms\tremaining: 533ms\n",
      "62:\tlearn: 1135.2595614\ttotal: 881ms\tremaining: 517ms\n",
      "63:\tlearn: 1135.2504173\ttotal: 888ms\tremaining: 499ms\n",
      "64:\tlearn: 1135.1705837\ttotal: 900ms\tremaining: 484ms\n",
      "65:\tlearn: 1135.0703944\ttotal: 910ms\tremaining: 469ms\n",
      "66:\tlearn: 1135.0065787\ttotal: 922ms\tremaining: 454ms\n",
      "67:\tlearn: 1134.9511656\ttotal: 933ms\tremaining: 439ms\n",
      "68:\tlearn: 1134.8740740\ttotal: 945ms\tremaining: 425ms\n",
      "69:\tlearn: 1134.7950255\ttotal: 957ms\tremaining: 410ms\n",
      "70:\tlearn: 1134.7251879\ttotal: 968ms\tremaining: 395ms\n",
      "71:\tlearn: 1134.6947186\ttotal: 978ms\tremaining: 380ms\n",
      "72:\tlearn: 1134.5968448\ttotal: 991ms\tremaining: 366ms\n",
      "73:\tlearn: 1134.4950054\ttotal: 1s\tremaining: 352ms\n",
      "74:\tlearn: 1134.4524427\ttotal: 1.01s\tremaining: 338ms\n",
      "75:\tlearn: 1134.3953124\ttotal: 1.03s\tremaining: 324ms\n",
      "76:\tlearn: 1134.3655647\ttotal: 1.04s\tremaining: 310ms\n",
      "77:\tlearn: 1134.3082543\ttotal: 1.05s\tremaining: 296ms\n",
      "78:\tlearn: 1134.2814950\ttotal: 1.06s\tremaining: 282ms\n",
      "79:\tlearn: 1134.2494705\ttotal: 1.07s\tremaining: 268ms\n",
      "80:\tlearn: 1134.1957339\ttotal: 1.08s\tremaining: 254ms\n",
      "81:\tlearn: 1134.1428461\ttotal: 1.09s\tremaining: 240ms\n",
      "82:\tlearn: 1134.1274873\ttotal: 1.1s\tremaining: 226ms\n",
      "83:\tlearn: 1134.0884874\ttotal: 1.11s\tremaining: 212ms\n",
      "84:\tlearn: 1134.0444359\ttotal: 1.13s\tremaining: 199ms\n",
      "85:\tlearn: 1133.9981805\ttotal: 1.14s\tremaining: 185ms\n",
      "86:\tlearn: 1133.9602226\ttotal: 1.15s\tremaining: 172ms\n",
      "87:\tlearn: 1133.8930695\ttotal: 1.16s\tremaining: 158ms\n",
      "88:\tlearn: 1133.8468675\ttotal: 1.17s\tremaining: 145ms\n",
      "89:\tlearn: 1133.8217019\ttotal: 1.18s\tremaining: 131ms\n",
      "90:\tlearn: 1133.7576322\ttotal: 1.19s\tremaining: 118ms\n",
      "91:\tlearn: 1133.7053455\ttotal: 1.21s\tremaining: 105ms\n",
      "92:\tlearn: 1133.6665684\ttotal: 1.22s\tremaining: 91.7ms\n",
      "93:\tlearn: 1133.6247772\ttotal: 1.23s\tremaining: 78.5ms\n",
      "94:\tlearn: 1133.6078302\ttotal: 1.24s\tremaining: 65.2ms\n",
      "95:\tlearn: 1133.5570932\ttotal: 1.25s\tremaining: 52.1ms\n",
      "96:\tlearn: 1133.5487633\ttotal: 1.26s\tremaining: 38.9ms\n",
      "97:\tlearn: 1133.5432886\ttotal: 1.26s\tremaining: 25.8ms\n",
      "98:\tlearn: 1133.5173737\ttotal: 1.27s\tremaining: 12.9ms\n",
      "99:\tlearn: 1133.4967929\ttotal: 1.29s\tremaining: 0us\n",
      "Finished training CAT\n",
      "Finished training XGB\n"
     ]
    }
   ],
   "source": [
    "grids = [lasso_grid_search,\n",
    "         ridge_grid_search,\n",
    "         knn_grid_search,\n",
    "         et_grid_search,\n",
    "         dt_grid_search,\n",
    "         rf_grid_search,\n",
    "         ada_grid_search,\n",
    "         gbr_grid_search,\n",
    "         lgbr_grid_search,\n",
    "         cat_grid_search,\n",
    "         xgb_grid_search\n",
    "         ]\n",
    "\n",
    "for pipe in grids:\n",
    "    pipe.fit(X_train,y_train)\n",
    "    print('Finished training {}'.format(pipe.estimator.steps[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will save results of the training and model evaluations will in txt and csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso Test metric: -831.474751537522\n",
      "lasso Best Params: {'LASSO__alpha': 1e-15}\n",
      "ridge Test metric: -831.4747515375153\n",
      "ridge Best Params: {'RIDGE__alpha': 0}\n",
      "knn Test metric: -867.9618955526126\n",
      "knn Best Params: {'KNN__weights': 'uniform', 'KNN__p': 2, 'KNN__n_neighbors': 9}\n",
      "et Test metric: -834.8307252454463\n",
      "et Best Params: {'ET__n_estimators': 200, 'ET__min_samples_split': 10, 'ET__min_samples_leaf': 2, 'ET__max_features': 1.0, 'ET__max_depth': 10}\n",
      "dt Test metric: -842.0657603170444\n",
      "dt Best Params: {'DT__min_samples_split': 10, 'DT__min_samples_leaf': 4, 'DT__max_depth': 5}\n",
      "rf Test metric: -851.7270905376032\n",
      "rf Best Params: {'RF__n_estimators': 50, 'RF__min_samples_split': 10, 'RF__min_samples_leaf': 2, 'RF__max_features': 'log2', 'RF__max_depth': 10, 'RF__bootstrap': False}\n",
      "ada Test metric: -882.1339456908137\n",
      "ada Best Params: {'ADA__n_estimators': 100, 'ADA__loss': 'linear', 'ADA__learning_rate': 0.01}\n",
      "gbr Test metric: -827.26930140518\n",
      "gbr Best Params: {'GBR__subsample': 0.9, 'GBR__n_estimators': 200, 'GBR__max_depth': 3, 'GBR__learning_rate': 0.1}\n",
      "lgbr Test metric: -828.3619156003826\n",
      "lgbr Best Params: {'LGBR__subsample': 1.0, 'LGBR__n_estimators': 50, 'LGBR__max_depth': 7, 'LGBR__learning_rate': 0.1, 'LGBR__colsample_bytree': 0.9}\n",
      "cat Test metric: -827.4898969632939\n",
      "cat Best Params: {'CAT__subsample': 0.8, 'CAT__learning_rate': 0.1, 'CAT__l2_leaf_reg': 5, 'CAT__iterations': 100, 'CAT__depth': 7}\n",
      "xgb Test metric: -818.759750043849\n",
      "xgb Best Params: {'XGB__subsample': 0.8, 'XGB__n_estimators': 50, 'XGB__max_depth': 3, 'XGB__learning_rate': 0.1, 'XGB__colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "grid_dict = {\n",
    "                0: 'lasso',\n",
    "                1: 'ridge',\n",
    "                2: 'knn',\n",
    "                3: 'et',\n",
    "                4: 'dt',\n",
    "                5: 'rf',\n",
    "                6: 'ada',\n",
    "                7: 'gbr',\n",
    "                8: 'lgbr',\n",
    "                9:'cat',\n",
    "                10:'xgb'\n",
    "                }\n",
    "\n",
    "results = []\n",
    "for i, model in enumerate(grids):\n",
    "    print('{} Test metric: {}'.format(grid_dict[i],\n",
    "    model.score(X_test,y_test)))\n",
    "    print('{} Best Params: {}'.format(grid_dict[i], model.best_params_))\n",
    "    y_true, y_pred = y_test, model.best_estimator_.predict(X_test),\n",
    "    \n",
    "    results.append({    \n",
    "        'iterator': i,\n",
    "        'model': grid_dict[i],\n",
    "        'best_params': model.best_params_,\n",
    "        'best_score': model.best_score_,\n",
    "        'mae': mean_absolute_error(y_true,y_pred),\n",
    "        'mse': mean_squared_error(y_true,y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true,y_pred)),\n",
    "        'r2': r2_score(y_true,y_pred)\n",
    "        })\n",
    "    \n",
    "results = sorted(results, key=itemgetter('best_score'), reverse=True) \n",
    "\n",
    " \n",
    "with open('results/5K_grid_search_results.txt', 'w') as file:\n",
    "    for result in results:\n",
    "        file.write(f\"Model: {result['model']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(\"Best Parameters:\\n\")\n",
    "        for key, value in result['best_params'].items():\n",
    "            file.write(f\"{key}: {value}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(f\"Best Score: {result['best_score']}\\n\")\n",
    "        file.write(f\"mae: {result['mae']}\\n\")\n",
    "        file.write(f\"mse: {result['mse']}\\n\")\n",
    "        file.write(f\"rmse: {result['rmse']}\\n\")\n",
    "        file.write(f\"r2: {result['r2']}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "models_scores = pd.DataFrame(results)\n",
    "models_scores = models_scores[['model','mae','mse','rmse','r2']]\n",
    "models_scores.to_csv('results/5K_models_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how did models performed on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model         mae           mse         rmse        r2\n",
      "0     xgb  818.759750  1.263474e+06  1124.043537  0.796820\n",
      "1     gbr  827.269301  1.261699e+06  1123.253784  0.797106\n",
      "2     cat  827.489897  1.261339e+06  1123.093665  0.797163\n",
      "3    lgbr  828.361916  1.259648e+06  1122.340284  0.797435\n",
      "4   ridge  831.474752  1.265864e+06  1125.106228  0.796436\n",
      "5   lasso  831.474752  1.265864e+06  1125.106228  0.796436\n",
      "6      et  834.830725  1.269443e+06  1126.695656  0.795860\n",
      "7      dt  842.065760  1.294528e+06  1137.773153  0.791826\n",
      "8      rf  851.727091  1.312969e+06  1145.848759  0.788861\n",
      "9     knn  867.961896  1.394560e+06  1180.914742  0.775740\n",
      "10    ada  882.133946  1.395814e+06  1181.445827  0.775538\n"
     ]
    }
   ],
   "source": [
    "print(models_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it appears that all models are performing well. We can observe R2 values within the range of 0.77-0.80, and MAE falls between 819-882 seconds (13.60 - 14.70 minutes), which is satisfactory given that we are attempting to predict marathon finish time based on age, gender, and 5k race time. If the model were trained with additional data, such as times for 10km and 21km, I anticipate that its performance would further improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Saving best model and making prediction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best model XGB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/5K_best_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = grids[results[0]['iterator']]\n",
    "print('Found best model {}'.format(best_model.estimator.steps[-1][0]))\n",
    "\n",
    "joblib.dump(best_model, 'models/5K_best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and making predictions for myself! üòÅ (Even though I can typically run 5 km faster, this would be my expected time during longer runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My predicted marathon time in hh:mm:ss is: 3:30:11\n",
      "My predicted marathon time in hh:mm:ss is: 3:28:46\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "best_model_loaded = joblib.load(\"models/5K_best_model.pkl\") \n",
    "\n",
    "# Testing mysef\n",
    "d = {'Age': [30], 'M/F': ['M'], '5K': ['0:23:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))\n",
    "\n",
    "# Testing mysef as female\n",
    "d = {'Age': [30], 'M/F': ['F'], '5K': ['0:23:00']}\n",
    "test = pd.DataFrame(data=d)\n",
    "\n",
    "predictions = best_model.best_estimator_.predict(test)\n",
    "print('My predicted marathon time in hh:mm:ss is:', timedelta(seconds=int(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current predictions from the model are reasonably accurate, with my best marathon time around 3:40:00. Considering this, training the model using either the 10 km time or the 21 km time may lead to even better results. Additionally, an interesting observation is that changing the gender from male to female seems to improve the predicted outcomes. This aligns with known information on the subject, as explored in the Exploratory Data Analysis (EDA) notebook, suggesting that females generally exhibit better endurance than males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A machine learning model has been successfully developed for predicting marathon finish times, leveraging features such as age, gender, and 5 km race time. The results demonstrate the model's effectiveness. Future efforts will involve the development of additional models to enhance predictive capabilities using alternative features, such as 10 km or 21 km race times. It is anticipated that these extended models will further improve the accuracy and precision of predictions for marathon finish times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
